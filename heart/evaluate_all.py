# heart/evaluate_all.py
"""
è¯„ä¼°æ‰€æœ‰ç®—æ³• - Object-level å’Œ Pixel-level
ä½¿ç”¨stardist.matchingè¿›è¡Œå®ä¾‹åŒ¹é…
åªè®¡ç®—: Recall, Pixel Recall, Missing Rate
"""
import numpy as np
from pathlib import Path
import pandas as pd
from tqdm import tqdm
from stardist.matching import matching

# é…ç½®
GT_DIR = Path("/ihome/jbwang/liy121/ifimage/heart/ground_truth_masks")
RESULTS_BASE = Path("/ihome/jbwang/liy121/ifimage/heart/benchmark_results")
OUTPUT_CSV = Path("/ihome/jbwang/liy121/ifimage/heart/evaluation_results.csv")

# ç®—æ³•åˆ—è¡¨
ALGORITHMS = [
    'cellpose',
    'cellpose_sam',
    'stardist',
    'omnipose',
    'watershed',
    'mesmer',
    'lacss',
    'microsam',
    'cellsam',
    'splinedist'
]

def calculate_pixel_recall(gt_mask, pred_mask):
    """
    è®¡ç®—Pixel-level Recall
    Pixel Recall = TP pixels / (TP pixels + FN pixels)
    """
    gt_binary = (gt_mask > 0).astype(bool)
    pred_binary = (pred_mask > 0).astype(bool)
    
    tp_pixels = np.logical_and(gt_binary, pred_binary).sum()
    fn_pixels = np.logical_and(gt_binary, ~pred_binary).sum()
    
    if (tp_pixels + fn_pixels) == 0:
        return 0.0
    
    pixel_recall = tp_pixels / (tp_pixels + fn_pixels)
    return pixel_recall

def evaluate_single(gt_mask, pred_mask, iou_threshold=0.5):
    """
    è¯„ä¼°å•å¼ å›¾åƒ
    
    Returns:
        dict with:
        - n_gt: GTå¯¹è±¡æ•°é‡
        - n_pred: é¢„æµ‹å¯¹è±¡æ•°é‡
        - n_matched: åŒ¹é…æˆåŠŸçš„å¯¹è±¡æ•°é‡
        - n_undetected: æœªæ£€æµ‹åˆ°çš„å¯¹è±¡æ•°é‡
        - object_recall: Object-level Recall
        - pixel_recall: Pixel-level Recall
        - missing_rate: Missing Rate (æœªæ£€æµ‹ç‡)
    """
    n_gt = len(np.unique(gt_mask)) - 1  # æ’é™¤èƒŒæ™¯0
    n_pred = len(np.unique(pred_mask)) - 1
    
    if n_gt == 0:
        return {
            'n_gt': 0,
            'n_pred': n_pred,
            'n_matched': 0,
            'n_undetected': 0,
            'object_recall': 0.0,
            'pixel_recall': 0.0,
            'missing_rate': 0.0
        }
    
    # ä½¿ç”¨stardist.matchingè¿›è¡Œå®ä¾‹åŒ¹é…
    matched = matching(gt_mask, pred_mask, thresh=iou_threshold)
    
    # matchedåŒ…å«: tp, fp, fnç­‰ä¿¡æ¯
    n_matched = matched.tp  # True Positives (æˆåŠŸåŒ¹é…çš„GTå¯¹è±¡)
    n_undetected = matched.fn  # False Negatives (æœªæ£€æµ‹åˆ°çš„GTå¯¹è±¡)
    
    # Object-level Recall
    object_recall = n_matched / n_gt if n_gt > 0 else 0.0
    
    # Missing Rate
    missing_rate = n_undetected / n_gt if n_gt > 0 else 0.0
    
    # Pixel-level Recall
    pixel_recall = calculate_pixel_recall(gt_mask, pred_mask)
    
    return {
        'n_gt': n_gt,
        'n_pred': n_pred,
        'n_matched': n_matched,
        'n_undetected': n_undetected,
        'object_recall': object_recall,
        'pixel_recall': pixel_recall,
        'missing_rate': missing_rate
    }

def find_predictions(algo_name, region, area, channel):
    """
    æŸ¥æ‰¾é¢„æµ‹æ–‡ä»¶
    æ”¯æŒä¸åŒçš„æ–‡ä»¶å‘½åæ ¼å¼
    """
    pred_dir = RESULTS_BASE / f"{algo_name}_predictions" / region
    
    # å°è¯•ä¸åŒçš„æ–‡ä»¶åæ ¼å¼
    possible_names = [
        f"{area}_{channel}_pred.npy",      # LA1_dapi_pred.npy
        f"{channel}-{area}_pred.npy",      # dapi-LA1_pred.npy
        f"{area}_pred.npy"                 # LA1_pred.npy (åªæœ‰area)
    ]
    
    for name in possible_names:
        pred_path = pred_dir / name
        if pred_path.exists():
            return pred_path
    
    return None

def main():
    print("=" * 70)
    print("ğŸ“Š Heart Dataset Evaluation")
    print("=" * 70)
    
    # åŠ è½½GT mapping
    gt_mapping = pd.read_csv(GT_DIR / 'file_mapping.csv')
    
    print(f"\nğŸ“‚ Ground Truth: {len(gt_mapping)} annotations")
    print(f"ğŸ“‚ Algorithms: {len(ALGORITHMS)}")
    print(f"ğŸ“‚ Algorithms: {', '.join(ALGORITHMS)}")
    
    all_results = []
    
    # éå†æ¯ä¸ªç®—æ³•
    for algo_name in ALGORITHMS:
        print(f"\n{'='*70}")
        print(f"ğŸ”¬ Evaluating: {algo_name}")
        print(f"{'='*70}")
        
        algo_dir = RESULTS_BASE / f"{algo_name}_predictions"
        if not algo_dir.exists():
            print(f"  âš ï¸  Prediction directory not found, skipping...")
            continue
        
        n_evaluated = 0
        n_missing = 0
        
        # éå†æ¯ä¸ªGT annotation
        for idx, row in tqdm(gt_mapping.iterrows(), 
                            total=len(gt_mapping),
                            desc=f"{algo_name}"):
            
            region = row['region']
            area = row['area']
            cell_type = row['cell_type']
            gt_path = Path(row['mask_absolute_path'])
            
            # æå–channelä¿¡æ¯
            # GTæ–‡ä»¶åæ ¼å¼: Epi-LA1_mask.npy
            channel = f"{cell_type.lower()}"  # æˆ–è€…ç”¨å…¶ä»–mapping
            
            # æŸ¥æ‰¾å¯¹åº”çš„é¢„æµ‹æ–‡ä»¶
            pred_path = find_predictions(algo_name, region, area, 'dapi')
            
            if pred_path is None:
                n_missing += 1
                continue
            
            try:
                # åŠ è½½masks
                gt_mask = np.load(gt_path)
                pred_mask = np.load(pred_path)
                
                # è¯„ä¼°
                metrics = evaluate_single(gt_mask, pred_mask, iou_threshold=0.5)
                
                # æ·»åŠ å…ƒä¿¡æ¯
                metrics.update({
                    'algorithm': algo_name,
                    'region': region,
                    'area': area,
                    'cell_type': cell_type,
                    'gt_path': str(gt_path),
                    'pred_path': str(pred_path)
                })
                
                all_results.append(metrics)
                n_evaluated += 1
                
            except Exception as e:
                print(f"\n  âœ— Failed {region}/{area}-{cell_type}: {e}")
                continue
        
        print(f"  âœ“ Evaluated: {n_evaluated}/{len(gt_mapping)}")
        if n_missing > 0:
            print(f"  âš ï¸  Missing predictions: {n_missing}")
    
    # ä¿å­˜ç»“æœ
    if all_results:
        results_df = pd.DataFrame(all_results)
        results_df.to_csv(OUTPUT_CSV, index=False)
        
        print("\n" + "=" * 70)
        print("ğŸ“Š EVALUATION SUMMARY")
        print("=" * 70)
        
        # æŒ‰ç®—æ³•æ±‡æ€»
        print("\nğŸ”¬ By Algorithm:")
        algo_summary = results_df.groupby('algorithm').agg({
            'object_recall': ['mean', 'std'],
            'pixel_recall': ['mean', 'std'],
            'missing_rate': ['mean', 'std'],
            'n_gt': 'sum',
            'n_matched': 'sum',
            'n_undetected': 'sum'
        }).round(4)
        print(algo_summary)
        
        # æŒ‰åŒºåŸŸæ±‡æ€»
        print("\nğŸ«€ By Region:")
        region_summary = results_df.groupby('region')[
            ['object_recall', 'pixel_recall', 'missing_rate']
        ].mean().round(4)
        print(region_summary)
        
        # æŒ‰ç»†èƒç±»å‹æ±‡æ€»
        print("\nğŸ§¬ By Cell Type:")
        celltype_summary = results_df.groupby('cell_type')[
            ['object_recall', 'pixel_recall', 'missing_rate']
        ].mean().round(4)
        print(celltype_summary)
        
        print(f"\nğŸ’¾ Results saved to: {OUTPUT_CSV}")
        print("=" * 70)
    else:
        print("\nâŒ No results to save!")

if __name__ == "__main__":
    main()