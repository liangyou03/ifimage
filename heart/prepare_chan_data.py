# heart/prepare_data.py
"""
å‡†å¤‡å¿ƒè„æ•°æ®é›† - æå–æ‰€æœ‰é€šé“å¹¶æ•´ç†æ–‡ä»¶ç»“æ„
ä½¿ç”¨tifffileè¯»å–å¤šé¡µTIFF
Channel 0: DAPI (nuclei)
Channel 1: ALDH1A2 (epicardial cell)
Channel 2: WGA (cell membrane)
Channel 3: CD45 (immune cell)
Channel 4: PDGFRB (mural cells)
"""
import numpy as np
from pathlib import Path
import pandas as pd
from tqdm import tqdm
from PIL import Image
import tifffile
import sys

sys.path.insert(0, str(Path(__file__).parent))
from config_heart import HeartConfig

# é€šé“å®šä¹‰
CHANNELS = {
    0: {'name': 'dapi', 'description': 'DAPI (nuclei)'},
    1: {'name': 'aldh1a2', 'description': 'ALDH1A2 (epicardial cell)'},
    2: {'name': 'wga', 'description': 'WGA (cell membrane)'},
    3: {'name': 'cd45', 'description': 'CD45 (immune cell)'},
    4: {'name': 'pdgfrb', 'description': 'PDGFRB (mural cells)'}
}

def load_multichannel_tiff(image_path):
    """ä½¿ç”¨tifffileåŠ è½½å¤šé€šé“TIFF"""
    with tifffile.TiffFile(image_path) as tif:
        data = tif.asarray()
        if data.ndim == 3 and data.shape[0] == 5:
            return data
        else:
            raise ValueError(f"Unexpected shape: {data.shape}, expected (5, H, W)")

def save_channel_tiff(channel_data, output_path):
    """ä¿å­˜å•é€šé“ä¸ºTIFF"""
    tifffile.imwrite(output_path, channel_data)

def split_channels(image_path, output_dir, area_name):
    """æ‹†åˆ†å¤šé€šé“å›¾åƒä¸ºå•ç‹¬çš„TIFFæ–‡ä»¶
    
    æ–‡ä»¶å‘½å: {area}_{channel}.tif
    ä¾‹å¦‚: LA1_dapi.tif, LA1_aldh1a2.tif
    """
    # åŠ è½½å›¾åƒ
    img_array = load_multichannel_tiff(image_path)
    n_channels, height, width = img_array.shape
    
    saved_files = {}
    channel_stats = []
    
    # ä¿å­˜æ¯ä¸ªé€šé“
    for ch_idx, ch_info in CHANNELS.items():
        channel_data = img_array[ch_idx, :, :]
        channel_name = ch_info['name']
        
        # è¾“å‡ºæ–‡ä»¶å: {area}_{channel}.tif
        output_filename = f"{area_name}_{channel_name}.tif"
        output_path = output_dir / output_filename
        
        # ä¿å­˜ä¸ºTIFF
        save_channel_tiff(channel_data, output_path)
        
        saved_files[channel_name] = str(output_path)
        
        # ç»Ÿè®¡ä¿¡æ¯
        n_nonzero = np.count_nonzero(channel_data)
        pct_nonzero = n_nonzero / channel_data.size * 100
        
        channel_stats.append({
            'channel': channel_name,
            'min': int(channel_data.min()),
            'max': int(channel_data.max()),
            'mean': float(channel_data.mean()),
            'std': float(channel_data.std()),
            'nonzero_pct': float(pct_nonzero)
        })
    
    return saved_files, channel_stats

def main():
    config = HeartConfig()
    
    print("=" * 70)
    print("ğŸ”¬ Preparing Heart Dataset - Extracting Channels from Multi-page TIFF")
    print("=" * 70)
    
    # åˆ›å»ºprocessedç›®å½•
    processed_dir = config.RAW_DIR.parent / 'processed'
    processed_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“‚ Input:  {config.RAW_DIR}")
    print(f"ğŸ“‚ Output: {processed_dir}")
    
    print(f"\nğŸ“º Channels to extract:")
    for ch_idx, ch_info in CHANNELS.items():
        print(f"  Channel {ch_idx}: {ch_info['description']}")
    
    # åŠ è½½mapping
    mapping_df = pd.read_csv(config.MAPPING_FILE)
    
    # è·å–æ‰€æœ‰å”¯ä¸€å›¾åƒï¼ˆæ¯ä¸ªareaåªå¤„ç†ä¸€æ¬¡ï¼‰
    unique_images = mapping_df.groupby(['region', 'area']).first().reset_index()
    
    print(f"\nğŸ“Š Found {len(unique_images)} unique images to process")
    print(f"ğŸ“Š Covering {len(mapping_df)} annotation regions")
    print(f"\nğŸ’¡ File naming: {{area}}_{{channel}}.tif")
    print(f"   Example: LA1_dapi.tif, LA1_aldh1a2.tif")
    
    # ä¸ºæ¯ä¸ªåŒºåŸŸåˆ›å»ºè¾“å‡ºç›®å½•
    for region in config.REGIONS:
        (processed_dir / region).mkdir(parents=True, exist_ok=True)
    
    all_data_info = []
    all_channel_stats = []
    failed = []
    
    # å¤„ç†æ¯ä¸ªå›¾åƒ
    for idx, row in tqdm(unique_images.iterrows(), total=len(unique_images), desc="Extracting"):
        region = row['region']
        area = row['area']  # e.g., LA1, RA2
        image_path = Path(row['image_absolute_path'])
        
        try:
            # æ‹†åˆ†é€šé“
            region_output_dir = processed_dir / region
            saved_files, channel_stats = split_channels(image_path, region_output_dir, area)
            
            # è®°å½•æ–‡ä»¶ä¿¡æ¯
            all_data_info.append({
                'region': region,
                'area': area,
                'original_image': str(image_path),
                **saved_files  # dapi, aldh1a2, wga, cd45, pdgfrb paths
            })
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            for stat in channel_stats:
                stat.update({
                    'region': region,
                    'area': area
                })
                all_channel_stats.append(stat)
            
        except Exception as e:
            failed.append({'region': region, 'area': area, 'error': str(e)})
            print(f"\n  âœ— Failed {region}/{area}: {e}")
            continue
    
    # ä¿å­˜æ•°æ®ä¿¡æ¯
    if all_data_info:
        data_info_df = pd.DataFrame(all_data_info)
        data_info_csv = processed_dir / 'data_info.csv'
        data_info_df.to_csv(data_info_csv, index=False)
        
        # ä¿å­˜é€šé“ç»Ÿè®¡
        channel_stats_df = pd.DataFrame(all_channel_stats)
        channel_stats_csv = processed_dir / 'channel_statistics.csv'
        channel_stats_df.to_csv(channel_stats_csv, index=False)
    else:
        print("\nâŒ No data extracted!")
        return
    
    print("\n" + "=" * 70)
    print("ğŸ“Š EXTRACTION SUMMARY")
    print("=" * 70)
    
    print(f"\nâœ… Successfully processed: {len(all_data_info)}/{len(unique_images)} images")
    print(f"ğŸ“ Total channel files created: {len(all_data_info) * 5}")
    
    if failed:
        print(f"\nâš ï¸  Failed: {len(failed)} images")
        for f in failed:
            print(f"  â€¢ {f['region']}/{f['area']}: {f['error']}")
    
    print(f"\nğŸ«€ Files by region:")
    for region in config.REGIONS:
        region_count = len(data_info_df[data_info_df['region'] == region])
        if region_count > 0:
            print(f"  â€¢ {region}: {region_count} images Ã— 5 channels = {region_count * 5} files")
    
    # é€šé“è´¨é‡ç»Ÿè®¡
    print(f"\nğŸ“Š Channel Statistics (across all images):")
    print(f"\n{'Channel':<40} {'MeanÂ±STD':>20} {'Max':>10} {'NonZero%':>10}")
    print(f"{'-'*82}")
    
    for ch_idx, ch_info in CHANNELS.items():
        ch_name = ch_info['name']
        ch_stats = channel_stats_df[channel_stats_df['channel'] == ch_name]
        if len(ch_stats) > 0:
            mean_val = ch_stats['mean'].mean()
            std_val = ch_stats['mean'].std()
            max_val = ch_stats['max'].max()
            nonzero = ch_stats['nonzero_pct'].mean()
            print(f"{ch_info['description']:<40} "
                  f"{mean_val:>8.1f}Â±{std_val:<8.1f} {max_val:>10} {nonzero:>9.1f}%")
    
    print(f"\nğŸ’¾ Data info saved to: {data_info_csv}")
    print(f"ğŸ’¾ Channel stats saved to: {channel_stats_csv}")
    
    # åˆ›å»ºå®Œæ•´çš„mappingæ–‡ä»¶ï¼ˆé“¾æ¥åˆ°GTï¼‰
    print("\nğŸ“ Creating complete data mapping with ground truth...")
    
    complete_mapping = []
    
    for _, data_row in data_info_df.iterrows():
        region = data_row['region']
        area = data_row['area']
        
        # ä¸ºæ¯ä¸ªcell typeåˆ›å»ºæ˜ å°„
        for cell_type in config.CELL_TYPES:
            gt_mask_path = config.GT_DIR / region / f"{cell_type}-{area}_mask.npy"
            
            if gt_mask_path.exists():
                complete_mapping.append({
                    'region': region,
                    'area': area,
                    'cell_type': cell_type,
                    'dapi': data_row['dapi'],
                    'aldh1a2': data_row['aldh1a2'],
                    'wga': data_row['wga'],
                    'cd45': data_row['cd45'],
                    'pdgfrb': data_row['pdgfrb'],
                    'gt_nuclei_mask': str(gt_mask_path)
                })
    
    complete_mapping_df = pd.DataFrame(complete_mapping)
    complete_mapping_csv = processed_dir / 'complete_mapping.csv'
    complete_mapping_df.to_csv(complete_mapping_csv, index=False)
    
    print(f"âœ… Complete mapping created: {complete_mapping_csv}")
    print(f"   {len(complete_mapping_df)} entries (image Ã— cell_type combinations)")
    
    # åˆ›å»ºREADME
    readme_path = processed_dir / 'README.md'
    with open(readme_path, 'w') as f:
        f.write("# Heart Dataset - Processed Data\n\n")
        f.write("## Channel Information\n\n")
        for ch_idx, ch_info in CHANNELS.items():
            f.write(f"- **Channel {ch_idx}**: {ch_info['description']}\n")
        f.write("\n## File Naming Convention\n\n")
        f.write("Files are named as: `{area}_{channel}.tif`\n\n")
        f.write("Examples:\n")
        f.write("- `LA1_dapi.tif` - Left Atrium area 1, DAPI channel\n")
        f.write("- `LA1_cd45.tif` - Left Atrium area 1, CD45 channel\n")
        f.write("- `RV2_aldh1a2.tif` - Right Ventricle area 2, ALDH1A2 channel\n")
        f.write("\n## File Structure\n\n")
        f.write("```\n")
        f.write("processed/\n")
        f.write("â”œâ”€â”€ LA/\n")
        f.write("â”‚   â”œâ”€â”€ LA1_dapi.tif\n")
        f.write("â”‚   â”œâ”€â”€ LA1_aldh1a2.tif\n")
        f.write("â”‚   â”œâ”€â”€ LA1_wga.tif\n")
        f.write("â”‚   â”œâ”€â”€ LA1_cd45.tif\n")
        f.write("â”‚   â”œâ”€â”€ LA1_pdgfrb.tif\n")
        f.write("â”‚   â””â”€â”€ ...\n")
        f.write("â”œâ”€â”€ RA/, LV/, RV/, SEP/\n")
        f.write("â”œâ”€â”€ data_info.csv            # All extracted channel files\n")
        f.write("â”œâ”€â”€ channel_statistics.csv   # Channel quality statistics\n")
        f.write("â”œâ”€â”€ complete_mapping.csv     # Links to ground truth masks\n")
        f.write("â””â”€â”€ README.md\n")
        f.write("```\n\n")
        f.write("## Data Files\n\n")
        f.write(f"- **data_info.csv**: {len(data_info_df)} images with all channel paths\n")
        f.write(f"- **complete_mapping.csv**: {len(complete_mapping_df)} entries linking channels to GT masks\n")
        f.write(f"- **channel_statistics.csv**: Quality metrics for each channel in each image\n\n")
        f.write("## Statistics\n\n")
        f.write(f"- Total images: {len(data_info_df)}\n")
        f.write(f"- Total channel files: {len(data_info_df) * 5}\n")
        f.write(f"- Regions: {', '.join(config.REGIONS)}\n")
        f.write(f"- Cell types with GT: {', '.join(config.CELL_TYPES)}\n")
    
    print(f"ğŸ“„ README created: {readme_path}")
    
    print("\n" + "=" * 70)
    print("âœ… Data preparation complete!")
    print("=" * 70)
    print("\nğŸ“‚ Output structure:")
    print(f"  {processed_dir}/")
    print(f"    â”œâ”€â”€ LA/, RA/, LV/, RV/, SEP/  (channel TIF files)")
    print(f"    â”‚   â””â”€â”€ {{area}}_{{channel}}.tif")
    print(f"    â”œâ”€â”€ data_info.csv             (file paths)")
    print(f"    â”œâ”€â”€ channel_statistics.csv    (quality metrics)")
    print(f"    â”œâ”€â”€ complete_mapping.csv      (links to GT)")
    print(f"    â””â”€â”€ README.md")
    print("\nğŸ“Š Next steps:")
    print("  1. Run find_gt_channel.py to identify which marker corresponds to each cell type")
    print("  2. Use processed/*_dapi.tif for nuclei segmentation")
    print("  3. Use processed/*_[marker].tif for cell segmentation")
    print("=" * 70)

if __name__ == "__main__":
    main()