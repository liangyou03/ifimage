# heart/sanity_check.py
"""
Sanity Checkè„šæœ¬ - æ£€æŸ¥é¢„æµ‹ç»“æœçš„è´¨é‡
æ£€æŸ¥Omniposeå’ŒCellSAMçš„é¢„æµ‹maskæ˜¯å¦æœ‰é—®é¢˜
"""
import numpy as np
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec

# é…ç½®
GT_DIR = Path("/ihome/jbwang/liy121/ifimage/heart/ground_truth_masks")
PROCESSED_DIR = Path("/ihome/jbwang/liy121/ifimage/heart/processed")
RESULTS_BASE = Path("/ihome/jbwang/liy121/ifimage/heart/benchmark_results")
OUTPUT_DIR = Path("/ihome/jbwang/liy121/ifimage/heart/sanity_check")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# éœ€è¦æ£€æŸ¥çš„ç®—æ³•
ALGORITHMS_TO_CHECK = ['omnipose', 'cellsam', 'cellpose_sam', 'stardist']

def load_image(image_path):
    """åŠ è½½å›¾åƒ"""
    import tifffile
    img = tifffile.imread(image_path)
    if img.ndim == 3:
        img = img[..., 0]
    return img

def analyze_mask(mask):
    """åˆ†æmaskçš„ç»Ÿè®¡ä¿¡æ¯"""
    n_objects = len(np.unique(mask)) - 1  # æ’é™¤èƒŒæ™¯
    object_sizes = []
    
    if n_objects > 0:
        for obj_id in np.unique(mask)[1:]:
            size = np.sum(mask == obj_id)
            object_sizes.append(size)
    
    return {
        'n_objects': n_objects,
        'total_pixels': np.sum(mask > 0),
        'coverage': np.sum(mask > 0) / mask.size * 100,
        'min_size': min(object_sizes) if object_sizes else 0,
        'max_size': max(object_sizes) if object_sizes else 0,
        'mean_size': np.mean(object_sizes) if object_sizes else 0,
        'median_size': np.median(object_sizes) if object_sizes else 0,
    }

def visualize_sample(sample_info, algorithms, output_path):
    """å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„æ‰€æœ‰ç®—æ³•ç»“æœ"""
    region = sample_info['region']
    area = sample_info['area']
    cell_type = sample_info['cell_type']
    
    # åŠ è½½æ•°æ®
    gt_mask = np.load(sample_info['gt_path'])
    
    # æ‰¾åˆ°å¯¹åº”çš„DAPIå›¾åƒ
    dapi_path = PROCESSED_DIR / region / f"{area}_dapi.tif"
    if not dapi_path.exists():
        print(f"  âš ï¸  DAPI image not found: {dapi_path}")
        return
    
    image = load_image(dapi_path)
    
    # åˆ›å»ºå­å›¾
    n_algos = len(algorithms) + 1  # +1 for GT
    fig = plt.figure(figsize=(5 * n_algos, 5))
    gs = GridSpec(1, n_algos, figure=fig)
    
    # æ˜¾ç¤ºåŸå›¾å’ŒGT
    ax0 = fig.add_subplot(gs[0, 0])
    ax0.imshow(image, cmap='gray')
    ax0.contour(gt_mask > 0, colors='red', linewidths=0.5)
    ax0.set_title(f'Image + GT\n{cell_type} (n={len(np.unique(gt_mask))-1})', 
                  fontsize=10, fontweight='bold')
    ax0.axis('off')
    
    # æ˜¾ç¤ºå„ç®—æ³•é¢„æµ‹
    for idx, algo in enumerate(algorithms, 1):
        pred_dir = RESULTS_BASE / f"{algo}_predictions" / region
        pred_path = pred_dir / f"{area}_dapi_pred.npy"
        
        ax = fig.add_subplot(gs[0, idx])
        ax.imshow(image, cmap='gray', alpha=0.5)
        
        if pred_path.exists():
            pred_mask = np.load(pred_path)
            stats = analyze_mask(pred_mask)
            
            # æ˜¾ç¤ºé¢„æµ‹maskçš„è¾¹ç•Œ
            ax.contour(pred_mask > 0, colors='cyan', linewidths=0.5)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            title = f'{algo.upper()}\nn={stats["n_objects"]}'
            title += f'\ncov={stats["coverage"]:.1f}%'
            if stats['n_objects'] > 0:
                title += f'\nsize={stats["mean_size"]:.0f}Â±{np.std([np.sum(pred_mask==i) for i in np.unique(pred_mask)[1:]]):.0f}'
            
            ax.set_title(title, fontsize=10)
            
            # å¦‚æœå¯¹è±¡æ•°ä¸º0ï¼ŒåŠ çº¢æ¡†è­¦å‘Š
            if stats['n_objects'] == 0:
                for spine in ax.spines.values():
                    spine.set_edgecolor('red')
                    spine.set_linewidth(3)
        else:
            ax.set_title(f'{algo.upper()}\nNOT FOUND', fontsize=10, color='red')
            ax.text(0.5, 0.5, 'Prediction\nNot Found', 
                   transform=ax.transAxes, ha='center', va='center',
                   fontsize=12, color='red', fontweight='bold')
        
        ax.axis('off')
    
    plt.suptitle(f'{region}/{area} - {cell_type}', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

def check_predictions():
    """æ£€æŸ¥æ‰€æœ‰é¢„æµ‹æ–‡ä»¶"""
    print("=" * 70)
    print("ğŸ” Sanity Check: Prediction Quality Analysis")
    print("=" * 70)
    
    # åŠ è½½GT mapping
    gt_mapping = pd.read_csv(GT_DIR / 'file_mapping.csv')
    
    all_stats = []
    
    # ç»Ÿè®¡æ¯ä¸ªç®—æ³•çš„é¢„æµ‹
    for algo in ALGORITHMS_TO_CHECK:
        print(f"\n{'='*70}")
        print(f"ğŸ”¬ Checking: {algo}")
        print(f"{'='*70}")
        
        pred_dir = RESULTS_BASE / f"{algo}_predictions"
        if not pred_dir.exists():
            print(f"  âš ï¸  Directory not found!")
            continue
        
        # ç»Ÿè®¡
        n_total = 0
        n_found = 0
        n_empty = 0
        n_with_predictions = 0
        
        for idx, row in gt_mapping.iterrows():
            region = row['region']
            area = row['area']
            cell_type = row['cell_type']
            
            pred_path = pred_dir / region / f"{area}_dapi_pred.npy"
            n_total += 1
            
            if pred_path.exists():
                n_found += 1
                mask = np.load(pred_path)
                stats = analyze_mask(mask)
                
                stats.update({
                    'algorithm': algo,
                    'region': region,
                    'area': area,
                    'cell_type': cell_type,
                    'pred_path': str(pred_path)
                })
                all_stats.append(stats)
                
                if stats['n_objects'] == 0:
                    n_empty += 1
                else:
                    n_with_predictions += 1
        
        print(f"\n  ğŸ“Š Statistics:")
        print(f"    Total GT annotations: {n_total}")
        print(f"    Prediction files found: {n_found} ({n_found/n_total*100:.1f}%)")
        print(f"    Empty predictions (n=0): {n_empty} ({n_empty/n_found*100:.1f}% of found)")
        print(f"    Valid predictions (n>0): {n_with_predictions} ({n_with_predictions/n_found*100:.1f}% of found)")
        
        if n_empty > 0:
            print(f"    âš ï¸  WARNING: {n_empty} predictions are empty!")
    
    # ä¿å­˜ç»Ÿè®¡CSV
    if all_stats:
        stats_df = pd.DataFrame(all_stats)
        stats_csv = OUTPUT_DIR / 'prediction_statistics.csv'
        stats_df.to_csv(stats_csv, index=False)
        print(f"\nğŸ’¾ Statistics saved to: {stats_csv}")
        
        # è¯¦ç»†ç»Ÿè®¡
        print("\n" + "=" * 70)
        print("ğŸ“Š DETAILED STATISTICS")
        print("=" * 70)
        
        for algo in ALGORITHMS_TO_CHECK:
            algo_df = stats_df[stats_df['algorithm'] == algo]
            if len(algo_df) == 0:
                continue
            
            print(f"\n{algo.upper()}:")
            print(f"  Total predictions: {len(algo_df)}")
            print(f"  Empty (n=0): {(algo_df['n_objects']==0).sum()}")
            print(f"  Mean objects: {algo_df['n_objects'].mean():.1f} Â± {algo_df['n_objects'].std():.1f}")
            print(f"  Mean coverage: {algo_df['coverage'].mean():.1f}% Â± {algo_df['coverage'].std():.1f}%")
            print(f"  Mean object size: {algo_df['mean_size'].mean():.1f} pixels")
    
    return stats_df if all_stats else None

def visualize_samples(stats_df, n_samples=5):
    """å¯è§†åŒ–å‡ ä¸ªæ ·æœ¬è¿›è¡Œå¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("ğŸ“Š Generating Visual Comparisons")
    print("=" * 70)
    
    # åŠ è½½GT mapping
    gt_mapping = pd.read_csv(GT_DIR / 'file_mapping.csv')
    
    # é€‰æ‹©æ ·æœ¬ï¼š
    # 1. éšæœºæ ·æœ¬
    # 2. Omniposeå¤±è´¥çš„æ ·æœ¬
    # 3. CellSAMå¤±è´¥çš„æ ·æœ¬
    
    samples_to_check = []
    
    # éšæœºé€‰æ‹©ä¸€äº›
    random_samples = gt_mapping.sample(min(3, len(gt_mapping)))
    for _, row in random_samples.iterrows():
        samples_to_check.append({
            'region': row['region'],
            'area': row['area'],
            'cell_type': row['cell_type'],
            'gt_path': row['mask_absolute_path'],
            'type': 'random'
        })
    
    # Omniposeç©ºé¢„æµ‹çš„æ ·æœ¬
    if stats_df is not None:
        omni_empty = stats_df[(stats_df['algorithm'] == 'omnipose') & 
                              (stats_df['n_objects'] == 0)]
        for _, row in omni_empty.head(2).iterrows():
            samples_to_check.append({
                'region': row['region'],
                'area': row['area'],
                'cell_type': row['cell_type'],
                'gt_path': gt_mapping[
                    (gt_mapping['region'] == row['region']) &
                    (gt_mapping['area'] == row['area']) &
                    (gt_mapping['cell_type'] == row['cell_type'])
                ]['mask_absolute_path'].values[0],
                'type': 'omnipose_empty'
            })
        
        # CellSAMç©ºé¢„æµ‹çš„æ ·æœ¬
        cellsam_empty = stats_df[(stats_df['algorithm'] == 'cellsam') & 
                                 (stats_df['n_objects'] == 0)]
        for _, row in cellsam_empty.head(2).iterrows():
            samples_to_check.append({
                'region': row['region'],
                'area': row['area'],
                'cell_type': row['cell_type'],
                'gt_path': gt_mapping[
                    (gt_mapping['region'] == row['region']) &
                    (gt_mapping['area'] == row['area']) &
                    (gt_mapping['cell_type'] == row['cell_type'])
                ]['mask_absolute_path'].values[0],
                'type': 'cellsam_empty'
            })
    
    # ç”Ÿæˆå¯è§†åŒ–
    for idx, sample in enumerate(samples_to_check[:n_samples]):
        print(f"\n  Visualizing sample {idx+1}/{min(n_samples, len(samples_to_check))}: "
              f"{sample['region']}/{sample['area']} - {sample['cell_type']} ({sample['type']})")
        
        output_path = OUTPUT_DIR / f"visual_check_{idx+1}_{sample['region']}_{sample['area']}_{sample['cell_type']}.png"
        visualize_sample(sample, ALGORITHMS_TO_CHECK, output_path)
        print(f"    Saved: {output_path.name}")

def main():
    # 1. æ£€æŸ¥é¢„æµ‹æ–‡ä»¶
    stats_df = check_predictions()
    
    # 2. å¯è§†åŒ–æ ·æœ¬
    if stats_df is not None:
        visualize_samples(stats_df, n_samples=10)
    
    print("\n" + "=" * 70)
    print("âœ… Sanity Check Complete!")
    print(f"ğŸ“ Results saved to: {OUTPUT_DIR}")
    print("=" * 70)

if __name__ == "__main__":
    main()