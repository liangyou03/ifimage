{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7c80ac5-8bac-48c9-b749-5067482fa09d",
   "metadata": {},
   "source": [
    "# Cell Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d68dce",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "print(\"ðŸ Python executable:\", sys.executable)\n",
    "print(\"ðŸ“¦ Environment path:\", os.environ.get('CONDA_PREFIX', 'Not in conda env'))\n",
    "print(\"ðŸ’» Hostname:\", os.uname().nodename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9d923-d087-4c91-b126-b2ed837bd67d",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "from evaluation_tasks import evaluate_cell_benchmark\n",
    "\n",
    "# ---------------- cfg ----------------\n",
    "thr = np.arange(0.50, 0.96, 0.05)\n",
    "ap_cols = [f\"AP@{t:.2f}\" for t in thr]\n",
    "cyto_preds: Dict[str, Path] = {\n",
    "    \"CellposeSAM\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"CellposeSAM Unrefined\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction\"),\n",
    "    \"StarDist\":  Path(\"/ihome/jbwang/liy121/ifimage/02_stardist_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"CellSAM\":   Path(\"/ihome/jbwang/liy121/ifimage/03_cellsam_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"MESMER\":    Path(\"/ihome/jbwang/liy121/ifimage/04_mesmer_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"Watershed\": Path(\"/ihome/jbwang/liy121/ifimage/06_watershed_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"Omnipose\":  Path(\"/ihome/jbwang/liy121/ifimage/07_omnipose_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"LACSS\":     Path(\"/ihome/jbwang/liy121/ifimage/011_lacss/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    # \"HoVerNet\":  Path(\"/ihome/jbwang/liy121/ifimage/09_hovernet_benchmark/cyto_prediction\"),\n",
    "    \"SplineDist\":Path(\"/ihome/jbwang/liy121/ifimage/08_splinedist_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"MicroSAM\":Path(\"/ihome/jbwang/liy121/ifimage/012_microsam_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "}\n",
    "dataset_dir = \"/ihome/jbwang/liy121/ifimage/00_dataset_withoutpecam\"\n",
    "out_dir = Path(\"/ihome/jbwang/liy121/ifimage/plots/eva\")\n",
    "boundary_scales: Tuple[float, ...] = (1.0, 2.0)\n",
    "ap_thresholds: Tuple[float, ...] = tuple(np.round(thr, 2))\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------- cache helpers -------------\n",
    "def _sig_name(cyto_pred_dirs: Dict[str, Path],\n",
    "              ap_thresholds: Tuple[float, ...],\n",
    "              boundary_scales: Tuple[float, ...]) -> str:\n",
    "    algos = \"-\".join(sorted(cyto_pred_dirs.keys()))\n",
    "    thr_s = \"_\".join(f\"{t:.2f}\" for t in ap_thresholds)\n",
    "    bnd_s = \"_\".join(f\"{b:.1f}\" for b in boundary_scales)\n",
    "    return f\"cyto__algos={algos}__thr={thr_s}__bnd={bnd_s}\"\n",
    "\n",
    "def _candidate_paths(out_root: Path, sig: str):\n",
    "    per_img_csv = out_root / f\"{sig}__per_img.csv\"\n",
    "    sum_csv     = out_root / f\"{sig}__summary.csv\"\n",
    "    per_img_par = out_root / f\"{sig}__per_img.parquet\"\n",
    "    sum_par     = out_root / f\"{sig}__summary.parquet\"\n",
    "    return (per_img_csv, sum_csv, per_img_par, sum_par)\n",
    "\n",
    "def _read_first_existing(per: Path, summ: Path, per_par: Path, summ_par: Path):\n",
    "    if per.exists() and summ.exists():\n",
    "        return pd.read_csv(per), pd.read_csv(summ)\n",
    "    if per_par.exists() and summ_par.exists():\n",
    "        return pd.read_parquet(per_par), pd.read_parquet(summ_par)\n",
    "    return None, None\n",
    "\n",
    "def _save_both(per_img: pd.DataFrame, summary: pd.DataFrame, per: Path, summ: Path, per_par: Path, summ_par: Path):\n",
    "    per_img.to_csv(per, index=False)\n",
    "    summary.to_csv(summ, index=False)\n",
    "    per_img.to_parquet(per_par, index=False)\n",
    "    summary.to_parquet(summ_par, index=False)\n",
    "\n",
    "# ------------- load-or-run -------------\n",
    "sig = _sig_name(cyto_preds, ap_thresholds, boundary_scales)\n",
    "per_csv, sum_csv, per_par, sum_par = _candidate_paths(out_dir, sig)\n",
    "per_img_cyto, sum_cyto = _read_first_existing(per_csv, sum_csv, per_par, sum_par)\n",
    "\n",
    "if per_img_cyto is None or sum_cyto is None:\n",
    "    per_img_cyto, sum_cyto = evaluate_cell_benchmark(\n",
    "        dataset_dir=dataset_dir,\n",
    "        cyto_pred_dirs=cyto_preds,\n",
    "        ap_thresholds=ap_thresholds,\n",
    "        boundary_scales=boundary_scales,\n",
    "        max_workers=8,\n",
    "        out_dir=str(out_dir),\n",
    "        verbose=True,\n",
    "    )\n",
    "    _save_both(per_img_cyto, sum_cyto, per_csv, sum_csv, per_par, sum_par)\n",
    "\n",
    "# ------------- curve + plot -------------\n",
    "ap_cols_present = [c for c in ap_cols if c in per_img_cyto.columns]\n",
    "curve = per_img_cyto.groupby(\"algorithm\")[ap_cols_present].mean()\n",
    "mAP = curve.mean(axis=1)\n",
    "\n",
    "print(\"[PLOT] algorithms:\", list(curve.index))\n",
    "print(\"[PLOT] AP columns:\", ap_cols_present)\n",
    "print(\"[PLOT] mAP sorted:\\n\", mAP.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc09144-fa1b-449f-af6e-a0dff9c6c5a6",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "try:\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "except Exception:\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"legend.fontsize\": 9,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.3,\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.dpi\": 200,\n",
    "    })\n",
    "\n",
    "if curve.empty:\n",
    "    raise ValueError(\"`curve` is empty. Did per_img_cyto/groupby succeed?\")\n",
    "if 'mAP' not in locals():\n",
    "    mAP = curve.mean(axis=1)\n",
    "\n",
    "# ------------- PLOT -------------\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "line_by_algo = {}\n",
    "for algo, row in curve.iterrows():\n",
    "    ln, = ax.plot(thr, row.values, marker='o', linewidth=2,\n",
    "                  label=f\"{algo} (mAP={mAP[algo]:.03f})\")\n",
    "    line_by_algo[algo] = ln\n",
    "\n",
    "#ax.set_title(\"Cell benchmark â€” overall\")\n",
    "ax.set_xlabel(\"IoU Threshold\")\n",
    "ax.set_ylabel(\"Average Precision\")\n",
    "ax.set_xlim(thr.min(), thr.max())\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.minorticks_on()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# ------------- LEGEND: sort high â†’ low by mAP -------------\n",
    "sorted_algos = sorted(mAP.index, key=lambda k: mAP[k], reverse=True)\n",
    "handles = [line_by_algo[a] for a in sorted_algos]\n",
    "labels  = [f\"{a} (mAP={mAP[a]:.03f})\" for a in sorted_algos]\n",
    "ax.legend(handles, labels, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# ------------- SAVE FIGURES -------------\n",
    "# Respect your earlier out_dir if defined; else fall back to ./figs\n",
    "try:\n",
    "    # `out_dir` was passed to evaluate_cell_benchmark; reuse it if present\n",
    "    out_dir = Path(out_dir)  # may already be a Path or str in your session\n",
    "except NameError:\n",
    "    out_dir = Path(\"./figs\")\n",
    "\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "pdf_path = out_dir / \"03_cellseg_overall_metrics.pdf\"\n",
    "png_path = out_dir / \"03_cellseg_overall_metrics.png\"\n",
    "\n",
    "fig.savefig(pdf_path, format=\"pdf\", transparent=True)\n",
    "fig.savefig(png_path, format=\"png\", dpi=300, transparent=True)\n",
    "\n",
    "print(f\"Saved:\\n  {pdf_path}\\n  {png_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9b88208-6f7f-4396-9d55-2746bd8d4ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Marker Only Eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a32db-8183-41f3-aabf-325578edffbe",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "from evaluation_tasks import evaluate_cell_benchmark\n",
    "\n",
    "# ---------------- cfg ----------------\n",
    "thr = np.arange(0.50, 0.96, 0.05)\n",
    "ap_cols = [f\"AP@{t:.2f}\" for t in thr]\n",
    "\n",
    "cyto_preds_2ch: Dict[str, Path] = {\n",
    "    \"CellposeSAM\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction_refined_mean_GMM\"),\n",
    "    \"CellposeSAM Unrefined\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction\"),\n",
    "    \"StarDist\":  Path(\"/ihome/jbwang/liy121/ifimage/02_stardist_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"CellSAM\":   Path(\"/ihome/jbwang/liy121/ifimage/03_cellsam_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"MESMER\":    Path(\"/ihome/jbwang/liy121/ifimage/04_mesmer_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"Watershed\": Path(\"/ihome/jbwang/liy121/ifimage/06_watershed_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"Omnipose\":  Path(\"/ihome/jbwang/liy121/ifimage/07_omnipose_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"LACSS\":     Path(\"/ihome/jbwang/liy121/ifimage/011_lacss/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"SplineDist\":Path(\"/ihome/jbwang/liy121/ifimage/08_splinedist_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"MicroSAM\":  Path(\"/ihome/jbwang/liy121/ifimage/012_microsam_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8afce-0ba9-4f4d-8890-273b3d5e4456",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# marker-onlyï¼ˆä½ çš„ markeronly ç»“æžœæ–‡ä»¶å¤¹ï¼‰\n",
    "cyto_preds_marker: Dict[str, Path] = {\n",
    "    \"CellposeSAM\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/markeronly\"),\n",
    "    \"CellposeSAM Unrefined\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/markeronly\"),\n",
    "    \"StarDist\":  Path(\"/ihome/jbwang/liy121/ifimage/02_stardist_benchmark/markeronly\"),\n",
    "    \"CellSAM\":   Path(\"/ihome/jbwang/liy121/ifimage/03_cellsam_benchmark/markeronly\"),\n",
    "    \"MESMER\":    Path(\"/ihome/jbwang/liy121/ifimage/04_mesmer_benchmark/markeronly\"),\n",
    "    \"Watershed\": Path(\"/ihome/jbwang/liy121/ifimage/06_watershed_benchmark/markeronly\"),\n",
    "    \"Omnipose\":  Path(\"/ihome/jbwang/liy121/ifimage/07_omnipose_benchmark/markeronly\"),\n",
    "    \"LACSS\":     Path(\"/ihome/jbwang/liy121/ifimage/011_lacss/markeronly\"),\n",
    "    \"SplineDist\":Path(\"/ihome/jbwang/liy121/ifimage/08_splinedist_benchmark/markeronly\"),\n",
    "    \"MicroSAM\":  Path(\"/ihome/jbwang/liy121/ifimage/012_microsam_benchmark/markeronly\"),\n",
    "}\n",
    "\n",
    "dataset_dir = \"/ihome/jbwang/liy121/ifimage/00_dataset_withoutpecam\"\n",
    "out_dir = Path(\"/ihome/jbwang/liy121/ifimage/plots/eva2\")\n",
    "boundary_scales: Tuple[float, ...] = (1.0, 2.0)\n",
    "ap_thresholds: Tuple[float, ...] = tuple(np.round(thr, 2))\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _sig_name(cyto_pred_dirs: Dict[str, Path],\n",
    "              ap_thresholds: Tuple[float, ...],\n",
    "              boundary_scales: Tuple[float, ...],\n",
    "              variant: str) -> str:\n",
    "    algos = \"-\".join(sorted(cyto_pred_dirs.keys()))\n",
    "    thr_s = \"_\".join(f\"{t:.2f}\" for t in ap_thresholds)\n",
    "    bnd_s = \"_\".join(f\"{b:.1f}\" for b in boundary_scales)\n",
    "    return f\"cyto__algos={algos}__thr={thr_s}__bnd={bnd_s}__variant={variant}\"\n",
    "\n",
    "def _candidate_paths(out_root: Path, sig: str):\n",
    "    per_img_csv = out_root / f\"{sig}__per_img.csv\"\n",
    "    sum_csv     = out_root / f\"{sig}__summary.csv\"\n",
    "    per_img_par = out_root / f\"{sig}__per_img.parquet\"\n",
    "    sum_par     = out_root / f\"{sig}__summary.parquet\"\n",
    "    return (per_img_csv, sum_csv, per_img_par, sum_par)\n",
    "\n",
    "def _read_first_existing(per: Path, summ: Path, per_par: Path, summ_par: Path):\n",
    "    if per.exists() and summ.exists():\n",
    "        return pd.read_csv(per), pd.read_csv(summ)\n",
    "    if per_par.exists() and summ_par.exists():\n",
    "        return pd.read_parquet(per_par), pd.read_parquet(summ_par)\n",
    "    return None, None\n",
    "\n",
    "def _save_both(per_img: pd.DataFrame, summary: pd.DataFrame, per: Path, summ: Path, per_par: Path, summ_par: Path):\n",
    "    per_img.to_csv(per, index=False)\n",
    "    summary.to_csv(summ, index=False)\n",
    "    per_img.to_parquet(per_par, index=False)\n",
    "    summary.to_parquet(summ_par, index=False)\n",
    "\n",
    "def _run_or_load(cyto_pred_dirs: Dict[str, Path], variant: str):\n",
    "    sig = _sig_name(cyto_pred_dirs, ap_thresholds, boundary_scales, variant)\n",
    "    per_csv, sum_csv, per_par, sum_par = _candidate_paths(out_dir, sig)\n",
    "    per_img, summ = _read_first_existing(per_csv, sum_csv, per_par, sum_par)\n",
    "    if per_img is None or summ is None:\n",
    "        per_img, summ = evaluate_cell_benchmark(\n",
    "            dataset_dir=dataset_dir,\n",
    "            cyto_pred_dirs=cyto_pred_dirs,\n",
    "            ap_thresholds=ap_thresholds,\n",
    "            boundary_scales=boundary_scales,\n",
    "            max_workers=4,\n",
    "            out_dir=str(out_dir),\n",
    "            verbose=True,\n",
    "        )\n",
    "        _save_both(per_img, summ, per_csv, sum_csv, per_par, sum_par)\n",
    "    per_img[\"variant\"] = variant\n",
    "    return per_img, summ\n",
    "\n",
    "# per_img_2ch, sum_2ch = _run_or_load(cyto_preds_2ch, \"2channel\")\n",
    "per_img_mk,  sum_mk  = _run_or_load(cyto_preds_marker, \"markeronly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba67d60-562b-43a6-b526-e94771f1fca1",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "per_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6593ce-0e43-407b-8ba5-a9eef3fce45e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "per_img_cyto[\"variant\"] = \"2channel\"\n",
    "per_all = pd.concat([per_img_cyto, per_img_mk], ignore_index=True)\n",
    "\n",
    "\n",
    "def _is_olig2_row(df: pd.DataFrame) -> pd.Series:\n",
    "    if \"cell_type\" in df.columns:\n",
    "        return df[\"cell_type\"].astype(str).str.lower().str.contains(\"olig2\")\n",
    "    for col in [\"base\"]:\n",
    "        if col in df.columns:\n",
    "            return df[col].astype(str).str.lower().str.contains(\"olig2\")\n",
    "    return pd.Series(False, index=df.index)\n",
    "\n",
    "mask_olig2 = _is_olig2_row(per_all)\n",
    "per_olig2  = per_all[mask_olig2].copy()\n",
    "per_alltypes = per_all.copy()  # å…¨éƒ¨ç»†èƒžç±»åž‹\n",
    "\n",
    "# ------------- æ›²çº¿ä¸Ž mAP è®¡ç®—å‡½æ•° -------------\n",
    "def _curve_and_map(df: pd.DataFrame):\n",
    "    ap_present = [c for c in ap_cols if c in df.columns]\n",
    "    curve = df.groupby([\"algorithm\", \"variant\"])[ap_present].mean()\n",
    "    mAP = curve.mean(axis=1)\n",
    "    return curve, mAP, ap_present\n",
    "\n",
    "# === (1) Olig2ï¼š2ch vs marker-only å¯¹æ¯” ===\n",
    "curve_olig2, mAP_olig2, ap_present_olig2 = _curve_and_map(per_olig2)\n",
    "\n",
    "# ç”» AP æ›²çº¿ï¼ˆæ¯ä¸ªç®—æ³•ä¸¤æ¡çº¿ï¼š2ch vs marker-onlyï¼‰\n",
    "plt.figure(figsize=(7,5))\n",
    "algs = sorted(per_olig2[\"algorithm\"].unique())\n",
    "for algo in algs:\n",
    "    for variant, ls in [(\"2channel\",\"-\"), (\"markeronly\",\"--\")]:\n",
    "        if (algo, variant) in curve_olig2.index:\n",
    "            y = curve_olig2.loc[(algo, variant), ap_present_olig2].values\n",
    "            x = [float(c.split(\"@\")[1]) for c in ap_present_olig2]\n",
    "            plt.plot(x, y, linestyle=ls, label=f\"{algo} ({variant})\")\n",
    "plt.xlabel(\"IoU threshold\")\n",
    "plt.ylabel(\"AP\")\n",
    "plt.title(\"Olig2: AP curves (2channel vs marker-only)\")\n",
    "plt.legend(fontsize=8, ncols=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"olig2_ap_curves_2ch_vs_markeronly.pdf\", dpi=200)\n",
    "\n",
    "# ç”» mAP å·®ï¼ˆ2ch - marker-onlyï¼‰\n",
    "plt.figure(figsize=(7,4))\n",
    "delta_records = []\n",
    "for algo in algs:\n",
    "    v2 = mAP_olig2.get((algo,\"2channel\"), np.nan)\n",
    "    vm = mAP_olig2.get((algo,\"markeronly\"), np.nan)\n",
    "    delta_records.append((algo, v2 - vm, v2, vm))\n",
    "delta_df = pd.DataFrame(delta_records, columns=[\"algorithm\",\"mAP_diff_2ch_minus_marker\",\"mAP_2ch\",\"mAP_marker\"])\n",
    "delta_df = delta_df.sort_values(\"mAP_diff_2ch_minus_marker\", ascending=False)\n",
    "plt.bar(delta_df[\"algorithm\"], delta_df[\"mAP_diff_2ch_minus_marker\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"mAP(2ch) - mAP(marker)\")\n",
    "plt.title(\"Olig2: mAP gap (2channel vs marker-only)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"olig2_map_gap_bar.pdf\", dpi=200)\n",
    "delta_df.to_csv(out_dir / \"olig2_map_gap_bar.csv\", index=False)\n",
    "\n",
    "# === (2) å…¨ç»†èƒžç±»åž‹ï¼šå„ç®—æ³•æ€»ä½“æ¯”è¾ƒï¼ˆåŒæ—¶å±•ç¤ºä¸¤ç§è¾“å…¥ï¼‰ ===\n",
    "curve_all, mAP_all, ap_present_all = _curve_and_map(per_alltypes)\n",
    "\n",
    "# mAP æŸ±çŠ¶å›¾ï¼šå„ç®—æ³•ä¸¤æ ¹æŸ±ï¼ˆ2ch ä¸Ž markerï¼‰\n",
    "plt.figure(figsize=(8,5))\n",
    "algs_all = sorted(per_alltypes[\"algorithm\"].unique())\n",
    "x = np.arange(len(algs_all))\n",
    "w = 0.38\n",
    "m2 = [mAP_all.get((a,\"2channel\"), np.nan) for a in algs_all]\n",
    "mm = [mAP_all.get((a,\"markeronly\"), np.nan) for a in algs_all]\n",
    "plt.bar(x - w/2, m2, width=w, label=\"2channel\")\n",
    "plt.bar(x + w/2, mm, width=w, label=\"marker-only\")\n",
    "plt.xticks(x, algs_all, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"All cell types: mAP by algorithm (2channel vs marker-only)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"alltypes_map_bar_2ch_vs_markeronly.pdf\", dpi=200)\n",
    "\n",
    "# è¾“å‡ºä¸€äº›å…³é”®ä¿¡æ¯åˆ°æŽ§åˆ¶å°\n",
    "print(\"[Olig2] algorithms:\", algs)\n",
    "print(\"[Olig2] AP columns:\", ap_present_olig2)\n",
    "print(\"[Olig2] mAP (2ch) top:\\n\", pd.Series({a: mAP_olig2.get((a,\"2channel\"), np.nan) for a in algs}).sort_values(ascending=False))\n",
    "print(\"[Olig2] mAP (marker) top:\\n\", pd.Series({a: mAP_olig2.get((a,\"markeronly\"), np.nan) for a in algs}).sort_values(ascending=False))\n",
    "print(\"[ALL] mAP table:\\n\", pd.DataFrame({\"algorithm\": algs_all, \"mAP_2ch\": m2, \"mAP_marker\": mm}).set_index(\"algorithm\").sort_values(\"mAP_2ch\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205378c-8650-44ad-a2ab-cdfbf01e743c",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "# --- style setup ---\n",
    "try:\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "except Exception:\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"legend.fontsize\": 9,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.3,\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.dpi\": 200,\n",
    "    })\n",
    "\n",
    "# --- draw AP vs IoU curves with mAP labels and sorted legend ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "variants = [\"2channel\", \"markeronly\"]\n",
    "colors = plt.cm.tab10.colors\n",
    "algs = sorted(per_olig2[\"algorithm\"].unique())\n",
    "color_map = {algo: colors[i % len(colors)] for i, algo in enumerate(algs)}\n",
    "\n",
    "for ax, variant in zip(axes, variants):\n",
    "    # æŽ’åºç®—æ³•ï¼šæŒ‰ mAP é«˜åˆ°ä½Ž\n",
    "    alg_sorted = sorted(\n",
    "        algs,\n",
    "        key=lambda a: mAP_olig2.get((a, variant), -np.inf),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    for algo in alg_sorted:\n",
    "        if (algo, variant) in curve_olig2.index:\n",
    "            y = curve_olig2.loc[(algo, variant), ap_present_olig2].values\n",
    "            x = [float(c.split(\"@\")[1]) for c in ap_present_olig2]\n",
    "            ax.plot(x, y, label=f\"{algo} (mAP={mAP_olig2[(algo, variant)]:.3f})\",\n",
    "                    color=color_map[algo], lw=1.8)\n",
    "    ax.set_xlabel(\"IoU threshold\")\n",
    "    ax.set_title(f\"Olig2: {variant.replace('only','-only')}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_ylabel(\"AP\")\n",
    "# legend æŽ’åºå·²ç»åœ¨ç»˜å›¾é¡ºåºä¸­å®žçŽ°ï¼ˆæŒ‰ mAP ä»Žé«˜åˆ°ä½Žï¼‰\n",
    "axes[1].legend(fontsize=8, ncols=1, loc=\"center left\", bbox_to_anchor=(1.02, 0.5))\n",
    "fig.suptitle(\"Olig2: AP vs IoU curves (2channel vs marker-only)\", fontsize=12)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85, right=0.80)\n",
    "plt.savefig(out_dir / \"olig2_ap_curves_2ch_vs_markeronly_sorted.pdf\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca7012-bf3c-4e41-af55-35319dd8036b",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# === (2) å…¨ç»†èƒžç±»åž‹ï¼šå„ç®—æ³•æ€»ä½“æ¯”è¾ƒï¼ˆåŒæ—¶å±•ç¤ºä¸¤ç§è¾“å…¥ï¼‰ ===\n",
    "curve_all, mAP_all, ap_present_all = _curve_and_map(per_alltypes)\n",
    "\n",
    "# mAP æŸ±çŠ¶å›¾ï¼šå„ç®—æ³•ä¸¤æ ¹æŸ±ï¼ˆ2ch ä¸Ž markerï¼‰\n",
    "plt.figure(figsize=(8,5))\n",
    "algs_all = sorted(per_alltypes[\"algorithm\"].unique())\n",
    "x = np.arange(len(algs_all))\n",
    "w = 0.38\n",
    "m2 = [mAP_all.get((a,\"2channel\"), np.nan) for a in algs_all]\n",
    "mm = [mAP_all.get((a,\"markeronly\"), np.nan) for a in algs_all]\n",
    "plt.bar(x - w/2, m2, width=w, label=\"2channel\")\n",
    "plt.bar(x + w/2, mm, width=w, label=\"marker-only\")\n",
    "plt.xticks(x, algs_all, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"All cell types: mAP by algorithm (2channel vs marker-only)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"alltypes_map_bar_2ch_vs_markeronly.pdf\", dpi=200)\n",
    "\n",
    "# === è¾“å‡ºå…³é”®ä¿¡æ¯ï¼ˆä¿ç•™ä¸‰ä½å°æ•°ï¼‰ ===\n",
    "pd.options.display.float_format = \"{:.3f}\".format  # å…¨å±€æŽ§åˆ¶æ˜¾ç¤ºç²¾åº¦\n",
    "\n",
    "map_olig2_2ch = pd.Series({a: mAP_olig2.get((a, \"2channel\"), np.nan) for a in algs}).round(3)\n",
    "map_olig2_mk  = pd.Series({a: mAP_olig2.get((a, \"markeronly\"), np.nan) for a in algs}).round(3)\n",
    "map_all_table = (\n",
    "    pd.DataFrame({\"algorithm\": algs_all, \"mAP_2ch\": m2, \"mAP_marker\": mm})\n",
    "    .round(3)\n",
    "    .set_index(\"algorithm\")\n",
    "    .sort_values(\"mAP_2ch\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n[Olig2] algorithms:\", algs)\n",
    "print(\"[Olig2] AP columns:\", ap_present_olig2)\n",
    "print(\"\\n[Olig2] mAP (2ch) top:\")\n",
    "print(map_olig2_2ch.sort_values(ascending=False))\n",
    "print(\"\\n[Olig2] mAP (marker-only) top:\")\n",
    "print(map_olig2_mk.sort_values(ascending=False))\n",
    "print(\"\\n[ALL] mAP table:\")\n",
    "print(map_all_table)\n",
    "\n",
    "# åŒæ—¶å¯¼å‡º mAP æ€»è¡¨ CSVï¼Œä¿ç•™ä¸‰ä½å°æ•°\n",
    "map_all_table.to_csv(out_dir / \"alltypes_map_table_rounded.csv\", float_format=\"%.3f\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86579352d4bda40e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Best Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12a4d9d4550278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:18:05.453465Z",
     "start_time": "2025-09-16T19:18:00.483755Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# All comments in ENGLISH\n",
    "from pathlib import Path\n",
    "import re, math, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# -------- CONFIG --------\n",
    "PER_IMG = per_img_cyto\n",
    "DATASET_DIR = Path(\"/ihome/jbwang/liy121/ifimage/00_dataset_withoutpecam\")\n",
    "PRED_REFINED_ROOT   = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\")\n",
    "PRED_UNREFINED_ROOT = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction\")\n",
    "GROUPS = {\"OLIG2\": r\"OLIG2\", \"NEUN\": r\"NEUN\", \"IBA1\": r\"IBA1\", \"GFAP\": r\"GFAP\"}\n",
    "OUT_PNG = Path(\"plots/best_per_celltype_report_3x4_whitebg.png\")\n",
    "OUT_PDF = Path(\"plots/best_per_celltype_report_3x4_whitebg.pdf\")\n",
    "BOUNDARY_W = 1.2\n",
    "FILL_ALPHA = 0.92  # stronger fills on white\n",
    "\n",
    "# -------- IO / IMAGE UTILS --------\n",
    "def _load_any(p: Path) -> np.ndarray:\n",
    "    return np.load(p) if p.suffix.lower()==\".npy\" else np.squeeze(tiff.imread(str(p)))\n",
    "\n",
    "def _to_gray(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 3:\n",
    "        x = (0.2126*x[...,0] + 0.7152*x[...,1] + 0.0722*x[...,2]) if x.shape[-1] >= 3 else x.max(-1)\n",
    "    elif x.ndim > 2:\n",
    "        x = x.squeeze()\n",
    "        if x.ndim > 2: x = x.max(0)\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def _norm01(x: np.ndarray) -> np.ndarray:\n",
    "    if x.size == 0: return x.astype(np.float32)\n",
    "    p1, p99 = np.percentile(x, [1, 99])\n",
    "    if p99 <= p1:\n",
    "        mn, mx = float(x.min()), float(x.max())\n",
    "        if mx <= mn: return np.zeros_like(x, np.float32)\n",
    "        p1, p99 = mn, mx\n",
    "    return np.clip((x - p1) / max(p99 - p1, 1e-6), 0, 1).astype(np.float32)\n",
    "\n",
    "def _first_match(root: Path, pats) -> Path | None:\n",
    "    for pat in pats:\n",
    "        hit = next(root.glob(pat), None)\n",
    "        if hit is not None: return hit\n",
    "    return None\n",
    "\n",
    "def find_raw_channels(base: str):\n",
    "    lead = base.split(\"_\", 1)[0].lower()\n",
    "    dapi_fp = _first_match(DATASET_DIR, [f\"{base}.tif\", f\"{base}.tiff\", f\"{base}.npy\",\n",
    "                                         f\"{base}_dapi.tif\", f\"{base}_dapi.tiff\", f\"{base}_dapi.npy\"])\n",
    "    marker_fp = _first_match(DATASET_DIR, [f\"{base}_{lead}.tif\", f\"{base}_{lead}.tiff\", f\"{base}_{lead}.npy\",\n",
    "                                           f\"{base}_marker.tif\", f\"{base}_marker.tiff\", f\"{base}_marker.npy\"])\n",
    "    d = _load_any(dapi_fp) if dapi_fp else None\n",
    "    m = _load_any(marker_fp) if marker_fp else None\n",
    "    return d, m\n",
    "\n",
    "def make_composite(dapi, marker):\n",
    "    # DAPI -> blue, Marker -> red\n",
    "    if dapi is None and marker is None: return None\n",
    "    d = _to_gray(dapi) if dapi is not None else None\n",
    "    m = _to_gray(marker) if marker is not None else None\n",
    "    if d is not None and m is not None:\n",
    "        h, w = min(d.shape[0], m.shape[0]), min(d.shape[1], m.shape[1])\n",
    "        d, m = d[:h,:w], m[:h,:w]\n",
    "    base = d if d is not None else m\n",
    "    H, W = base.shape\n",
    "    rgb = np.zeros((H, W, 3), np.float32)\n",
    "    if d is not None: rgb[...,2] = _norm01(d)  # blue\n",
    "    if m is not None: rgb[...,0] = _norm01(m)  # red\n",
    "    return rgb\n",
    "\n",
    "def stack_to_label(arr):\n",
    "    if arr.ndim == 3:\n",
    "        lab = np.zeros(arr.shape[1:], np.int32); k = 0\n",
    "        for i in range(arr.shape[0]):\n",
    "            m = arr[i] > 0\n",
    "            if m.any(): k += 1; lab[m] = k\n",
    "        return lab\n",
    "    return arr\n",
    "\n",
    "def find_gt(base):\n",
    "    p = DATASET_DIR / f\"{base}_cellbodies.npy\"\n",
    "    return p if p.exists() else next(DATASET_DIR.rglob(f\"{base}*cellbodies*.npy\"), None)\n",
    "\n",
    "def find_pred(base, root: Path):\n",
    "    p = root / f\"{base}_pred_cyto.npy\"\n",
    "    return p if p.exists() else next(root.rglob(f\"{base}*pred*cyto*.npy\"), None)\n",
    "\n",
    "# -------- PRETTY MASK RENDERING ON WHITE --------\n",
    "def _seed_from_text(s: str) -> int:\n",
    "    return int(hashlib.sha256(s.encode()).hexdigest()[:8], 16)\n",
    "\n",
    "def _pastel_palette(n: int, seed: int):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    hues = rng.random(n)\n",
    "    S, V = 0.35, 0.95\n",
    "    rgb = []\n",
    "    for h in hues:\n",
    "        i = int(h*6.0) % 6; f = h*6.0 - i\n",
    "        p = V*(1-S); q = V*(1-S*f); t = V*(1-S*(1-f))\n",
    "        if   i==0: r,g,b = V,t,p\n",
    "        elif i==1: r,g,b = q,V,p\n",
    "        elif i==2: r,g,b = p,V,t\n",
    "        elif i==3: r,g,b = p,q,V\n",
    "        elif i==4: r,g,b = t,p,V\n",
    "        else:      r,g,b = V,p,q\n",
    "        rgb.append((r,g,b))\n",
    "    return np.array(rgb, dtype=np.float32)\n",
    "\n",
    "def label_viz_on_white(lab: np.ndarray, *, seed_text: str, fill_alpha: float = FILL_ALPHA) -> np.ndarray:\n",
    "    H, W = lab.shape[:2]\n",
    "    img = np.ones((H, W, 3), np.float32)\n",
    "    ids = [i for i in np.unique(lab) if i != 0]\n",
    "    if not ids: return img\n",
    "    pal = _pastel_palette(len(ids), _seed_from_text(seed_text))\n",
    "    id2idx = {i:k for k,i in enumerate(ids)}\n",
    "    for i in ids:\n",
    "        m = (lab == i)\n",
    "        if not m.any(): continue\n",
    "        c = pal[id2idx[i]]\n",
    "        img[m] = img[m]*(1-fill_alpha) + c*fill_alpha\n",
    "    return img\n",
    "\n",
    "def draw_contours(ax, binary, color=\"k\", lw=1.1):\n",
    "    for cnt in find_contours(binary.astype(float), 0.5):\n",
    "        ax.plot(cnt[:,1], cnt[:,0], color=color, linewidth=lw, solid_capstyle=\"round\")\n",
    "\n",
    "# -------- TABLE --------\n",
    "def as_df(x):\n",
    "    if isinstance(x, dict):\n",
    "        parts = []\n",
    "        for algo, df in x.items():\n",
    "            if df is None or df.empty: continue\n",
    "            dfx = df.copy(); dfx[\"algorithm\"] = algo; parts.append(dfx)\n",
    "        return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    return x.copy()\n",
    "\n",
    "def infer_ap_cols(df):\n",
    "    ap = [c for c in df.columns if re.match(r\"^AP@\\d\\.\\d{2}$\", c)]\n",
    "    if not ap: raise ValueError(\"No AP@xx.xx columns found.\")\n",
    "    return sorted(ap, key=lambda c: float(c.split(\"@\")[1]))\n",
    "\n",
    "def per_image_scores(df: pd.DataFrame, base: str, algo: str):\n",
    "    ap_cols = infer_ap_cols(df)\n",
    "    sub = df[(df[\"base\"] == base) & (df[\"algorithm\"] == algo)]\n",
    "    if sub.empty: return np.nan, np.nan\n",
    "    r = sub.iloc[0]\n",
    "    mAP = pd.to_numeric(r[ap_cols], errors=\"coerce\").mean()\n",
    "    ap50 = float(r.get(\"AP@0.50\", np.nan))\n",
    "    return float(mAP), ap50\n",
    "\n",
    "df = as_df(PER_IMG)\n",
    "if \"base\" not in df.columns: raise ValueError(\"Missing 'base'\")\n",
    "if \"algorithm\" not in df.columns: df[\"algorithm\"] = \"model\"\n",
    "ap_cols = infer_ap_cols(df)\n",
    "df[\"_score\"] = pd.to_numeric(df[ap_cols].mean(axis=1), errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"_score\"])\n",
    "\n",
    "best = []\n",
    "for gname, pat in GROUPS.items():\n",
    "    sub = df[df[\"base\"].str.contains(pat, case=False, regex=True, na=False)]\n",
    "    best.append((gname, None if sub.empty else sub.loc[sub[\"_score\"].idxmax()]))\n",
    "\n",
    "# -------- FIGURE 3x4 --------\n",
    "cols = list(GROUPS.keys()); ncols = len(cols); nrows = 3\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(4.2*ncols, 3.9*nrows), squeeze=False)\n",
    "\n",
    "for j, (gname, row) in enumerate(best):\n",
    "    ax_raw, ax_ref, ax_unr = axes[0, j], axes[1, j], axes[2, j]\n",
    "\n",
    "    if row is None:\n",
    "        for ax in (ax_raw, ax_ref, ax_unr): ax.axis(\"off\")\n",
    "        ax_raw.set_title(f\"{gname}: no image\"); continue\n",
    "\n",
    "    base = str(row[\"base\"]); algo = str(row.get(\"algorithm\", \"model\"))\n",
    "    score = float(row[\"_score\"]); ap50_ref = float(row.get(\"AP@0.50\", np.nan))\n",
    "\n",
    "    # row 1: raw composite\n",
    "    comp = make_composite(*find_raw_channels(base))\n",
    "    if comp is None:\n",
    "        ax_raw.axis(\"off\"); ax_raw.set_title(f\"{gname} | {base}\\nraw missing\", fontsize=9)\n",
    "    else:\n",
    "        ax_raw.imshow(comp)\n",
    "        pretty_base = base.replace(\"_\", \" \").upper()\n",
    "        ax_raw.set_title(f\"{pretty_base}\", fontsize=12)\n",
    "        ax_raw.axis(\"off\")\n",
    "\n",
    "    # GT\n",
    "    gt_path = find_gt(base)\n",
    "    if gt_path is None or not gt_path.exists():\n",
    "        for ax, tag in ((ax_ref,\"refined\"), (ax_unr,\"unrefined\")):\n",
    "            ax.axis(\"off\"); ax.set_title(f\"{gname} | {base}\\n(no GT for {tag})\", fontsize=9)\n",
    "        continue\n",
    "    gt = stack_to_label(np.load(gt_path))\n",
    "\n",
    "    # row 2: refined\n",
    "    pr_ref_p = find_pred(base, PRED_REFINED_ROOT)\n",
    "    if pr_ref_p and pr_ref_p.exists():\n",
    "        pr_ref = stack_to_label(np.load(pr_ref_p))\n",
    "        h, w = min(gt.shape[0], pr_ref.shape[0]), min(gt.shape[1], pr_ref.shape[1])\n",
    "        gt2, pr_ref = gt[:h,:w], pr_ref[:h,:w]\n",
    "        ax_ref.imshow(label_viz_on_white(pr_ref, seed_text=base))\n",
    "        draw_contours(ax_ref, gt2>0, color=\"#222222\", lw=BOUNDARY_W)\n",
    "        ax_ref.set_title(f\"{algo} (refined)  mAP={score:.2f}  AP50={ap50_ref:.2f}\", fontsize=12)\n",
    "        ax_ref.axis(\"off\")\n",
    "    else:\n",
    "        ax_ref.axis(\"off\"); ax_ref.set_title(f\"{gname} | {base}\\n(no refined pred)\", fontsize=12)\n",
    "\n",
    "    # row 3: unrefined\n",
    "    pr_unr_p = find_pred(base, PRED_UNREFINED_ROOT)\n",
    "    if pr_unr_p and pr_unr_p.exists():\n",
    "        pr_unr = stack_to_label(np.load(pr_unr_p))\n",
    "        h, w = min(gt.shape[0], pr_unr.shape[0]), min(gt.shape[1], pr_unr.shape[1])\n",
    "        gt3, pr_unr = gt[:h,:w], pr_unr[:h,:w]\n",
    "        mAP_unr, ap50_unr = per_image_scores(df, base, \"Cellpose Unrefined\")\n",
    "        ax_unr.imshow(label_viz_on_white(pr_unr, seed_text=base+\"_unref\"))\n",
    "        draw_contours(ax_unr, gt3>0, color=\"#222222\", lw=BOUNDARY_W)\n",
    "        title_unr = \"Cellpose (unrefined)\"\n",
    "        if not np.isnan(mAP_unr):  title_unr += f\"  mAP={mAP_unr:.2f}\"\n",
    "        if not np.isnan(ap50_unr): title_unr += f\"  AP50={ap50_unr:.2f}\"\n",
    "        ax_unr.set_title(title_unr, fontsize=12)\n",
    "        ax_unr.axis(\"off\")\n",
    "    else:\n",
    "        ax_unr.axis(\"off\"); ax_unr.set_title(f\"{gname} | {base}\\n(no unrefined pred)\", fontsize=9)\n",
    "\n",
    "for ax in axes.ravel(): ax.set_xticks([]); ax.set_yticks([])\n",
    "fig.tight_layout()\n",
    "OUT_PNG.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(OUT_PNG, dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(OUT_PDF, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"[SAVED] {OUT_PNG}\")\n",
    "print(f\"[SAVED] {OUT_PDF}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41971e5-f390-4b0b-8823-c9059da8ef8c",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# All comments in ENGLISH\n",
    "from pathlib import Path\n",
    "import re, math, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# -------- CONFIG --------\n",
    "PER_IMG = per_img_cyto\n",
    "DATASET_DIR = Path(\"/ihome/jbwang/liy121/ifimage/00_dataset_withoutpecam\")\n",
    "cyto_preds: Dict[str, Path] = {\n",
    "    \"CellposeSAM\":  Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"StarDist\":  Path(\"/ihome/jbwang/liy121/ifimage/02_stardist_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"CellSAM\":   Path(\"/ihome/jbwang/liy121/ifimage/03_cellsam_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"MESMER\":    Path(\"/ihome/jbwang/liy121/ifimage/04_mesmer_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"Watershed\": Path(\"/ihome/jbwang/liy121/ifimage/06_watershed_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"Omnipose\":  Path(\"/ihome/jbwang/liy121/ifimage/07_omnipose_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"LACSS\":     Path(\"/ihome/jbwang/liy121/ifimage/011_lacss/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"HoVerNet\":  Path(\"/ihome/jbwang/liy121/ifimage/09_hovernet_benchmark/cyto_prediction\"),\n",
    "    \"SplineDist\":Path(\"/ihome/jbwang/liy121/ifimage/08_splinedist_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "    \"MicroSAM\":Path(\"/ihome/jbwang/liy121/ifimage/012_microsam_benchmark/refilter_outputs/feat-mean_thr-otsu_area-100_gate-off\"),\n",
    "}\n",
    "GROUPS = {\"OLIG2\": r\"OLIG2\", \"NEUN\": r\"NEUN\", \"IBA1\": r\"IBA1\", \"GFAP\": r\"GFAP\"}\n",
    "OUT_PNG = Path(\"plots/best_per_celltype_report_3x4_whitebg.png\")\n",
    "OUT_PDF = Path(\"plots/best_per_celltype_report_3x4_whitebg.pdf\")\n",
    "BOUNDARY_W = 1.2\n",
    "FILL_ALPHA = 0.92  # stronger fills on white\n",
    "\n",
    "# -------- IO / IMAGE UTILS --------\n",
    "def _load_any(p: Path) -> np.ndarray:\n",
    "    return np.load(p) if p.suffix.lower()==\".npy\" else np.squeeze(tiff.imread(str(p)))\n",
    "\n",
    "def _to_gray(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 3:\n",
    "        x = (0.2126*x[...,0] + 0.7152*x[...,1] + 0.0722*x[...,2]) if x.shape[-1] >= 3 else x.max(-1)\n",
    "    elif x.ndim > 2:\n",
    "        x = x.squeeze()\n",
    "        if x.ndim > 2: x = x.max(0)\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def _norm01(x: np.ndarray) -> np.ndarray:\n",
    "    if x.size == 0: return x.astype(np.float32)\n",
    "    p1, p99 = np.percentile(x, [1, 99])\n",
    "    if p99 <= p1:\n",
    "        mn, mx = float(x.min()), float(x.max())\n",
    "        if mx <= mn: return np.zeros_like(x, np.float32)\n",
    "        p1, p99 = mn, mx\n",
    "    return np.clip((x - p1) / max(p99 - p1, 1e-6), 0, 1).astype(np.float32)\n",
    "\n",
    "def _first_match(root: Path, pats) -> Path | None:\n",
    "    for pat in pats:\n",
    "        hit = next(root.glob(pat), None)\n",
    "        if hit is not None: return hit\n",
    "    return None\n",
    "\n",
    "def find_raw_channels(base: str):\n",
    "    lead = base.split(\"_\", 1)[0].lower()\n",
    "    dapi_fp = _first_match(DATASET_DIR, [f\"{base}.tif\", f\"{base}.tiff\", f\"{base}.npy\",\n",
    "                                         f\"{base}_dapi.tif\", f\"{base}_dapi.tiff\", f\"{base}_dapi.npy\"])\n",
    "    marker_fp = _first_match(DATASET_DIR, [f\"{base}_{lead}.tif\", f\"{base}_{lead}.tiff\", f\"{base}_{lead}.npy\",\n",
    "                                           f\"{base}_marker.tif\", f\"{base}_marker.tiff\", f\"{base}_marker.npy\"])\n",
    "    d = _load_any(dapi_fp) if dapi_fp else None\n",
    "    m = _load_any(marker_fp) if marker_fp else None\n",
    "    return d, m\n",
    "\n",
    "def make_composite(dapi, marker):\n",
    "    # DAPI -> blue, Marker -> red\n",
    "    if dapi is None and marker is None: return None\n",
    "    d = _to_gray(dapi) if dapi is not None else None\n",
    "    m = _to_gray(marker) if marker is not None else None\n",
    "    if d is not None and m is not None:\n",
    "        h, w = min(d.shape[0], m.shape[0]), min(d.shape[1], m.shape[1])\n",
    "        d, m = d[:h,:w], m[:h,:w]\n",
    "    base = d if d is not None else m\n",
    "    H, W = base.shape\n",
    "    rgb = np.zeros((H, W, 3), np.float32)\n",
    "    if d is not None: rgb[...,2] = _norm01(d)  # blue\n",
    "    if m is not None: rgb[...,0] = _norm01(m)  # red\n",
    "    return rgb\n",
    "\n",
    "def stack_to_label(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 3:\n",
    "        lab = np.zeros(arr.shape[1:], np.int32); k = 0\n",
    "        for i in range(arr.shape[0]):\n",
    "            m = arr[i] > 0\n",
    "            if m.any(): k += 1; lab[m] = k\n",
    "        return lab\n",
    "    return arr\n",
    "\n",
    "def find_gt(base):\n",
    "    p = DATASET_DIR / f\"{base}_cellbodies.npy\"\n",
    "    return p if p.exists() else next(DATASET_DIR.rglob(f\"{base}*cellbodies*.npy\"), None)\n",
    "\n",
    "def find_pred(base, root: Path):\n",
    "    p = root / f\"{base}_pred_cyto.npy\"\n",
    "    return p if p.exists() else next(root.rglob(f\"{base}*pred*cyto*.npy\"), None)\n",
    "\n",
    "# -------- TABLE UTILS --------\n",
    "def as_df(x):\n",
    "    if isinstance(x, dict):\n",
    "        parts = []\n",
    "        for algo, df in x.items():\n",
    "            if df is None or df.empty: continue\n",
    "            dfx = df.copy(); dfx[\"algorithm\"] = algo; parts.append(dfx)\n",
    "        return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    return x.copy()\n",
    "\n",
    "def infer_ap_cols(df):\n",
    "    ap = [c for c in df.columns if re.match(r\"^AP@\\d\\.\\d{2}$\", c)]\n",
    "    if not ap: raise ValueError(\"No AP@xx.xx columns found.\")\n",
    "    return sorted(ap, key=lambda c: float(c.split(\"@\")[1]))\n",
    "\n",
    "def per_image_scores(df: pd.DataFrame, base: str, algo: str):\n",
    "    ap_cols = infer_ap_cols(df)\n",
    "    sub = df[(df[\"base\"] == base) & (df[\"algorithm\"] == algo)]\n",
    "    if sub.empty: return np.nan, np.nan\n",
    "    r = sub.iloc[0]\n",
    "    mAP = pd.to_numeric(r[ap_cols], errors=\"coerce\").mean()\n",
    "    ap50 = float(r.get(\"AP@0.50\", np.nan))\n",
    "    return float(mAP), ap50\n",
    "\n",
    "# -------- LOAD & PICK BEST PER CELLTYPE --------\n",
    "df = as_df(PER_IMG)\n",
    "if \"base\" not in df.columns: raise ValueError(\"Missing 'base'\")\n",
    "if \"algorithm\" not in df.columns: df[\"algorithm\"] = \"model\"\n",
    "\n",
    "ap_cols = infer_ap_cols(df)\n",
    "df[\"_score\"] = pd.to_numeric(df[ap_cols].mean(axis=1), errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"_score\"])\n",
    "\n",
    "best = []  # list of (celltype, row) where row has 'base' and 'algorithm'\n",
    "for gname, pat in GROUPS.items():\n",
    "    sub = df[df[\"base\"].str.contains(pat, case=False, regex=True, na=False)]\n",
    "    best.append((gname, None if sub.empty else sub.loc[sub[\"_score\"].idxmax()]))\n",
    "\n",
    "# -------- FIGURE 3x4 --------\n",
    "cols = list(GROUPS.keys()); ncols = len(cols); nrows = 3\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(4.2*ncols, 3.9*nrows), squeeze=False)\n",
    "\n",
    "def draw_contours(ax, binary, color=\"k\", lw=1.1):\n",
    "    from skimage.measure import find_contours\n",
    "    for cnt in find_contours(binary.astype(float), 0.5):\n",
    "        ax.plot(cnt[:,1], cnt[:,0], color=color, linewidth=lw, solid_capstyle=\"round\")\n",
    "\n",
    "def label_viz_on_white(lab: np.ndarray, *, seed_text: str, fill_alpha: float = FILL_ALPHA) -> np.ndarray:\n",
    "    H, W = lab.shape[:2]\n",
    "    img = np.ones((H, W, 3), np.float32)\n",
    "    ids = [i for i in np.unique(lab) if i != 0]\n",
    "    if not ids: return img\n",
    "    rng = np.random.default_rng(int(hashlib.sha256(seed_text.encode()).hexdigest()[:8], 16))\n",
    "    hues = rng.random(len(ids)); S, V = 0.35, 0.95\n",
    "    def hsv2rgb(h):\n",
    "        i = int(h*6.0) % 6; f = h*6.0 - i\n",
    "        p = V*(1-S); q = V*(1-S*f); t = V*(1-S*(1-f))\n",
    "        return [(V,t,p),(q,V,p),(p,V,t),(p,q,V),(t,p,V),(V,p,q)][i]\n",
    "    pal = np.array([hsv2rgb(h) for h in hues], np.float32)\n",
    "    id2idx = {i:k for k,i in enumerate(ids)}\n",
    "    for i in ids:\n",
    "        m = (lab == i)\n",
    "        if m.any():\n",
    "            c = pal[id2idx[i]]\n",
    "            img[m] = img[m]*(1-fill_alpha) + c*fill_alpha\n",
    "    return img\n",
    "\n",
    "for j, (gname, row) in enumerate(best):\n",
    "    ax_raw, ax_best, ax_unref = axes[0, j], axes[1, j], axes[2, j]\n",
    "\n",
    "    if row is None:\n",
    "        for ax in (ax_raw, ax_best, ax_unref): ax.axis(\"off\")\n",
    "        ax_raw.set_title(f\"{gname}: no image\"); continue\n",
    "\n",
    "    base = str(row[\"base\"])\n",
    "    algo_best = str(row.get(\"algorithm\", \"Cellpose\"))\n",
    "    mAP_best, ap50_best = per_image_scores(df, base, algo_best)\n",
    "\n",
    "    # row 1: raw composite\n",
    "    comp = make_composite(*find_raw_channels(base))\n",
    "    if comp is None:\n",
    "        ax_raw.axis(\"off\"); ax_raw.set_title(f\"{gname} | {base}\\nraw missing\", fontsize=9)\n",
    "    else:\n",
    "        ax_raw.imshow(comp); ax_raw.axis(\"off\")\n",
    "        ax_raw.set_title(base.replace(\"_\", \" \").upper(), fontsize=12)\n",
    "\n",
    "    # load GT\n",
    "    gt_path = DATASET_DIR / f\"{base}_cellbodies.npy\"\n",
    "    if not gt_path.exists():\n",
    "        gt_path = next(DATASET_DIR.rglob(f\"{base}*cellbodies*.npy\"), None)\n",
    "    if gt_path is None or not gt_path.exists():\n",
    "        for ax, tag in ((ax_best,\"best\"), (ax_unref,\"unrefined\")):\n",
    "            ax.axis(\"off\"); ax.set_title(f\"{gname} | {base}\\n(no GT for {tag})\", fontsize=9)\n",
    "        continue\n",
    "    gt = stack_to_label(np.load(gt_path))\n",
    "\n",
    "    # row 2: BEST algorithm prediction from correct folder\n",
    "    root_best = cyto_preds.get(algo_best, None)\n",
    "    pr_best_p = find_pred(base, root_best) if root_best is not None else None\n",
    "    if pr_best_p and pr_best_p.exists():\n",
    "        pr_best = stack_to_label(np.load(pr_best_p))\n",
    "        # legacy: crop both to min shape\n",
    "        h, w = min(gt.shape[0], pr_best.shape[0]), min(gt.shape[1], pr_best.shape[1])\n",
    "        gt2, pr_best = gt[:h,:w], pr_best[:h,:w]\n",
    "        ax_best.imshow(label_viz_on_white(pr_best, seed_text=f\"{base}_{algo_best}\"))\n",
    "        draw_contours(ax_best, gt2>0, color=\"#222222\", lw=BOUNDARY_W)\n",
    "        title = f\"{algo_best} (best)  \"\n",
    "        if not np.isnan(mAP_best):  title += f\"mAP={mAP_best:.2f}  \"\n",
    "        if not np.isnan(ap50_best): title += f\"AP50={ap50_best:.2f}\"\n",
    "        ax_best.set_title(title.strip(), fontsize=12)\n",
    "        ax_best.axis(\"off\")\n",
    "    else:\n",
    "        ax_best.axis(\"off\"); ax_best.set_title(f\"{gname} | {base}\\n(no best pred found)\", fontsize=9)\n",
    "\n",
    "    # row 3: Cellpose Unrefined as common baseline\n",
    "    root_unref = cyto_preds[\"Cellpose Unrefined\"]\n",
    "    pr_unref_p = find_pred(base, root_unref)\n",
    "    if pr_unref_p and pr_unref_p.exists():\n",
    "        pr_unref = stack_to_label(np.load(pr_unref_p))\n",
    "        h, w = min(gt.shape[0], pr_unref.shape[0]), min(gt.shape[1], pr_unref.shape[1])\n",
    "        gt3, pr_unref = gt[:h,:w], pr_unref[:h,:w]\n",
    "        mAP_unref, ap50_unref = per_image_scores(df, base, \"Cellpose Unrefined\")\n",
    "        ax_unref.imshow(label_viz_on_white(pr_unref, seed_text=f\"{base}_CellposeUnref\"))\n",
    "        draw_contours(ax_unref, gt3>0, color=\"#222222\", lw=BOUNDARY_W)\n",
    "        title_unref = \"Cellpose (unrefined)  \"\n",
    "        if not np.isnan(mAP_unref):  title_unref += f\"mAP={mAP_unref:.2f}  \"\n",
    "        if not np.isnan(ap50_unref): title_unref += f\"AP50={ap50_unref:.2f}\"\n",
    "        ax_unref.set_title(title_unref.strip(), fontsize=12)\n",
    "        ax_unref.axis(\"off\")\n",
    "    else:\n",
    "        ax_unref.axis(\"off\"); ax_unref.set_title(f\"{gname} | {base}\\n(no unrefined pred)\", fontsize=9)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "OUT_PNG.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(OUT_PNG, dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(OUT_PDF, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"[SAVED] {OUT_PNG}\")\n",
    "print(f\"[SAVED] {OUT_PDF}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7941d1b-1df1-4c44-8d7a-750b63b1d2d6",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ===== Compare ALL images: Cellpose vs Cellpose Unrefined =====\n",
    "from matplotlib.backends.backend_pdf import PdfPages  # not used now, kept for reference\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUT_ROOT = Path(\"figs/cellpose_compare_pages\")   # parent folder\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# collect bases\n",
    "all_bases = sorted(df[\"base\"].dropna().astype(str).unique().tolist())\n",
    "\n",
    "def _safe_stack_to_label(p):\n",
    "    if p is None or (not p.exists()):\n",
    "        return None\n",
    "    arr = np.load(p)\n",
    "    return stack_to_label(arr)\n",
    "\n",
    "def _match_size(a, b):\n",
    "    if a is None or b is None:\n",
    "        return a, b\n",
    "    h = min(a.shape[0], b.shape[0]); w = min(a.shape[1], b.shape[1])\n",
    "    return a[:h, :w], b[:h, :w]\n",
    "\n",
    "for k, base in enumerate(all_bases, 1):\n",
    "    # per-image scores\n",
    "    mAP_ref, ap50_ref = per_image_scores(df, base, \"Cellpose\")\n",
    "    mAP_unr, ap50_unr = per_image_scores(df, base, \"Cellpose Unrefined\")\n",
    "\n",
    "    # I/O\n",
    "    comp = make_composite(*find_raw_channels(base))\n",
    "    gt_path = find_gt(base)\n",
    "    gt = np.load(gt_path) if (gt_path and gt_path.exists()) else None\n",
    "    if gt is not None: gt = stack_to_label(gt)\n",
    "\n",
    "    pr_ref = _safe_stack_to_label(find_pred(base, PRED_REFINED_ROOT))\n",
    "    pr_unr = _safe_stack_to_label(find_pred(base, PRED_UNREFINED_ROOT))\n",
    "\n",
    "    # align\n",
    "    gt_ref = gt\n",
    "    if gt is not None and pr_ref is not None:\n",
    "        gt_ref, pr_ref = _match_size(gt, pr_ref)\n",
    "    gt_unr = gt\n",
    "    if gt is not None and pr_unr is not None:\n",
    "        gt_unr, pr_unr = _match_size(gt, pr_unr)\n",
    "\n",
    "    # figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5), squeeze=False)\n",
    "    ax_raw, ax_ref, ax_unr = axes[0]\n",
    "\n",
    "    # raw\n",
    "    if comp is not None:\n",
    "        ax_raw.imshow(comp); ax_raw.axis(\"off\")\n",
    "        ax_raw.set_title(base.replace(\"_\", \" \").upper(), fontsize=12)\n",
    "    else:\n",
    "        ax_raw.axis(\"off\"); ax_raw.set_title(f\"{base}\\n(raw missing)\", fontsize=10)\n",
    "\n",
    "    # refined\n",
    "    if pr_ref is not None:\n",
    "        ax_ref.imshow(label_viz_on_white(pr_ref, seed_text=base+\"_cellpose_ref\"))\n",
    "        if gt_ref is not None:\n",
    "            draw_contours(ax_ref, gt_ref > 0, color=\"#222222\", lw=BOUNDARY_W)\n",
    "        title = \"Cellpose (refined)\"\n",
    "        if not np.isnan(mAP_ref):  title += f\"  mAP={mAP_ref:.2f}\"\n",
    "        if not np.isnan(ap50_ref): title += f\"  AP50={ap50_ref:.2f}\"\n",
    "        ax_ref.set_title(title, fontsize=12)\n",
    "        ax_ref.axis(\"off\")\n",
    "    else:\n",
    "        ax_ref.axis(\"off\"); ax_ref.set_title(f\"{base}\\n(no refined pred)\", fontsize=10)\n",
    "\n",
    "    # unrefined\n",
    "    if pr_unr is not None:\n",
    "        ax_unr.imshow(label_viz_on_white(pr_unr, seed_text=base+\"_cellpose_unref\"))\n",
    "        if gt_unr is not None:\n",
    "            draw_contours(ax_unr, gt_unr > 0, color=\"#222222\", lw=BOUNDARY_W)\n",
    "        title = \"Cellpose (unrefined)\"\n",
    "        if not np.isnan(mAP_unr):  title += f\"  mAP={mAP_unr:.2f}\"\n",
    "        if not np.isnan(ap50_unr): title += f\"  AP50={ap50_unr:.2f}\"\n",
    "        ax_unr.set_title(title, fontsize=12)\n",
    "        ax_unr.axis(\"off\")\n",
    "    else:\n",
    "        ax_unr.axis(\"off\"); ax_unr.set_title(f\"{base}\\n(no unrefined pred)\", fontsize=10)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # --- save per-base into a subfolder by marker prefix ---\n",
    "    marker_prefix = base.split(\"_\", 1)[0].upper()  # e.g., OLIG2/NEUN/IBA1/GFAP\n",
    "    out_dir = OUT_ROOT / marker_prefix\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig.savefig(out_dir / f\"{base}.png\", dpi=250, bbox_inches=\"tight\")\n",
    "    fig.savefig(out_dir / f\"{base}.pdf\", dpi=250, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    if k % 20 == 0 or k == len(all_bases):\n",
    "        print(f\"[{k}/{len(all_bases)}] saved {marker_prefix}/{base}.pdf + .png\")\n",
    "\n",
    "print(f\"[SAVED per-page PDFs/PNGs] {OUT_ROOT}  (grouped by marker)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "703837c5-87f9-4ca6-b562-8c958920f119",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cell benchmark: AP-vs-IoU per cell-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef80bb3-2d6b-4c9d-b0c8-465a15f10b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T00:48:26.890546Z",
     "start_time": "2025-09-16T00:48:26.425364Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# â€”â€” Cell benchmark: AP-vs-IoU per cell-type (facet plot) â€”â€”\n",
    "# Legend ranked highâ†’low by mAP, \"sci\" style, and save to PDF/PNG.\n",
    "# All comments are in ENGLISH.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- STYLE: scientific look ----------\n",
    "try:\n",
    "    plt.style.use(['science', 'no-latex'])  # Requires SciencePlots\n",
    "except Exception:\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.8,\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.dpi\": 120,\n",
    "    })\n",
    "\n",
    "# ---------- GROUPS ----------\n",
    "groups = {\n",
    "    \"OLIG2\": r\"OLIG2\",\n",
    "    \"NEUN\":  r\"NEUN\",\n",
    "    \"IBA1\":  r\"IBA1\",\n",
    "    \"GFAP\":  r\"GFAP\",\n",
    "    # \"PECAM\": r\"PECAM\",  # commented intentionally\n",
    "}\n",
    "\n",
    "ncols = 2\n",
    "nrows = math.ceil(len(groups) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(12, 10), squeeze=False)\n",
    "\n",
    "# ---------- PLOT ----------\n",
    "for ax, (gname, pattern) in zip(axes.ravel(), groups.items()):\n",
    "    sub = per_img_cyto[per_img_cyto[\"base\"].str.contains(pattern, case=False, regex=True, na=False)]\n",
    "    if sub.empty:\n",
    "        ax.set_title(f\"Cell type: {gname} (no images)\")\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    grp_curve = sub.groupby(\"algorithm\")[ap_cols].mean()\n",
    "    grp_mAP = grp_curve.mean(axis=1)\n",
    "\n",
    "    line_by_algo = {}\n",
    "    for algo, row in grp_curve.iterrows():\n",
    "        ln, = ax.plot(thr, row.values, marker='o', linewidth=2,\n",
    "                      label=f\"{algo} (mAP={grp_mAP[algo]:.02f})\")\n",
    "        line_by_algo[algo] = ln\n",
    "\n",
    "    # Aesthetics\n",
    "    ax.set_title(f\"Cell type: {gname}\")\n",
    "    ax.set_xlabel(\"IoU Threshold\")\n",
    "    ax.set_ylabel(\"Average Precision\")\n",
    "    ax.set_xlim(thr.min(), thr.max())\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # ---------- LEGEND: rank high â†’ low by mAP ----------\n",
    "    sorted_algos = sorted(grp_mAP.index, key=lambda k: grp_mAP[k], reverse=True)\n",
    "    handles = [line_by_algo[a] for a in sorted_algos]\n",
    "    labels  = [f\"{a} (mAP={grp_mAP[a]:.02f})\" for a in sorted_algos]\n",
    "    ax.legend(handles, labels, fontsize=8, frameon=False)\n",
    "\n",
    "# Hide unused axes\n",
    "for j in range(len(groups), nrows * ncols):\n",
    "    axes.ravel()[j].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# ---------- SAVE ----------\n",
    "try:\n",
    "    out_dir = Path(out_dir)  # reuse from earlier if available\n",
    "except NameError:\n",
    "    out_dir = Path(\"./figs\")\n",
    "\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "pdf_path = out_dir / \"celltype_AP_vs_IoU_facets.pdf\"\n",
    "png_path = out_dir / \"celltype_AP_vs_IoU_facets.png\"\n",
    "\n",
    "fig.savefig(pdf_path, format=\"pdf\", transparent=True)\n",
    "fig.savefig(png_path, format=\"png\", dpi=300, transparent=True)\n",
    "\n",
    "print(f\"Saved:\\n  {pdf_path}\\n  {png_path}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54c82a70090feaf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nuclei Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bad686-07ce-4d35-acdc-025333e9de21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T01:03:52.693861Z",
     "start_time": "2025-09-16T00:56:07.832800Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from evaluation_core import EvalConfig, evaluate_all\n",
    "import numpy as np\n",
    "\n",
    "PRED_SUBDIR = \"nuclei_prediction\"\n",
    "\n",
    "# Define prediction directories\n",
    "pred_dirs = {\n",
    "    \"CellposeSAM\": Path(f\"01_cellpose_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"StarDist\": Path(f\"02_stardist_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"CellSAM\": Path(f\"03_cellsam_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"Mesmer\": Path(f\"04_mesmer_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"Watershed\": Path(f\"06_watershed_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"Omnipose\": Path(f\"07_omnipose_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"SplineDist\": Path(f\"08_splinedist_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"Hover-Net\": Path(f\"09_hovernet_benchmark/{PRED_SUBDIR}\"),\n",
    "    \"LACSS\": Path(f\"011_lacss/{PRED_SUBDIR}\"),\n",
    "    \"MicroSam\": Path(f\"012_microsam_benchmark/{PRED_SUBDIR}\"),\n",
    "}\n",
    "\n",
    "# Common strip tokens (ordered from longest to shortest)\n",
    "COMMON_STRIPS = [\n",
    "    \"_microsam_nuc\", \"_pred_nuclei\", \"_pred_nuc\",\n",
    "    \"_prediction\", \"_refined\", \"_filtered\", \"_filter\",\n",
    "    \"_nuclei\", \"_nuc\",\n",
    "]\n",
    "\n",
    "# Method-specific strip tokens\n",
    "pred_strip = {\n",
    "    \"CellposeSAM\": [\n",
    "        \"_cp_masks\", \"_cp_mask\",\n",
    "        \"_labels\", \"_label\",\n",
    "        \"_masks\", \"_mask\",\n",
    "    ] + COMMON_STRIPS,\n",
    "    \n",
    "    \"StarDist\": [\n",
    "        \"_stardist_nuclei\", \"_stardist_nuc\", \"_stardist\",\n",
    "    ] + COMMON_STRIPS,\n",
    "    \n",
    "    \"CellSAM\": [\n",
    "        \"_cellsam\", \"_sam\",\n",
    "        \"_masks\", \"_mask\", \"_labels\", \"_label\",\n",
    "    ] + COMMON_STRIPS,\n",
    "    \n",
    "    # All others use common strips + method name\n",
    "    **{method: COMMON_STRIPS + [f\"_{method.lower()}\"] \n",
    "       for method in [\"Mesmer\", \"Watershed\", \"Omnipose\", \"SplineDist\", \"LACSS\", \"Hover-Net\",\"MicroSam\"]}\n",
    "}\n",
    "\n",
    "cfg = EvalConfig(\n",
    "    gt_dir=Path(\"00_dataset\"),\n",
    "    pred_dirs=pred_dirs,\n",
    "    gt_glob=\"*_dapimultimask.npy\",\n",
    "    pred_glob=\"*.npy\",\n",
    "    gt_strip=[\"_dapimultimask\"],\n",
    "    pred_strip=pred_strip,\n",
    "    ap_thresholds=tuple(np.round(np.arange(0.50, 0.96, 0.05), 2)),\n",
    "    boundary_scales=(1.0, 2.0),\n",
    ")\n",
    "\n",
    "per_img_nuc, sum_nuc = evaluate_all(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d486e-83fd-4a35-a59a-e0ffadd11fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T01:04:38.325532Z",
     "start_time": "2025-09-16T01:04:38.315185Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# All comments in ENGLISH\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- STYLE HELPERS ----------\n",
    "def _apply_science_style():\n",
    "    \"\"\"\n",
    "    Apply a scientific figure style:\n",
    "      - Prefer 'science' (SciencePlots) if installed, with 'no-latex'\n",
    "      - Otherwise, use a clean Matplotlib fallback suitable for publications.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.style.use(['science', 'no-latex'])  # requires the 'SciencePlots' package\n",
    "    except Exception:\n",
    "        mpl.rcParams.update({\n",
    "            \"font.family\": \"sans-serif\",\n",
    "            \"font.size\": 10,\n",
    "            \"axes.titlesize\": 11,\n",
    "            \"axes.labelsize\": 10,\n",
    "            \"legend.fontsize\": 9,\n",
    "            \"xtick.direction\": \"in\",\n",
    "            \"ytick.direction\": \"in\",\n",
    "            \"axes.spines.top\": False,\n",
    "            \"axes.spines.right\": False,\n",
    "            \"axes.grid\": True,\n",
    "            \"grid.alpha\": 0.3,\n",
    "            \"grid.linestyle\": \"-\",\n",
    "            \"savefig.bbox\": \"tight\",\n",
    "            \"figure.dpi\": 200,\n",
    "        })\n",
    "\n",
    "def _save_both(fig: plt.Figure, base: Path, dpi: int = 300, transparent: bool = True):\n",
    "    \"\"\"\n",
    "    Save figure as both PDF (vector) and PNG (raster).\n",
    "    `base` can be a full filename (with or without extension) or a basename.\n",
    "    \"\"\"\n",
    "    base = Path(base)\n",
    "    if base.suffix:  # if user passed something like \"plot.png\", strip suffix for twin saves\n",
    "        base = base.with_suffix(\"\")\n",
    "    base.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pdf_path = base.with_suffix(\".pdf\")\n",
    "    png_path = base.with_suffix(\".png\")\n",
    "    fig.savefig(pdf_path, format=\"pdf\", transparent=transparent)\n",
    "    fig.savefig(png_path, format=\"png\", dpi=dpi, transparent=transparent)\n",
    "    print(f\"Saved:\\n  {pdf_path}\\n  {png_path}\")\n",
    "\n",
    "\n",
    "# ---------- YOUR HELPERS (tweaked only minimally) ----------\n",
    "def _as_perimg_df(per_img):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      - dict: {algo_name: per-image DataFrame}, OR\n",
    "      - DataFrame: with or without 'algorithm' column.\n",
    "    Return a single DataFrame with an 'algorithm' column.\n",
    "    \"\"\"\n",
    "    if isinstance(per_img, dict):\n",
    "        parts = []\n",
    "        for algo, df in per_img.items():\n",
    "            if df is None or len(df) == 0:\n",
    "                continue\n",
    "            df = df.copy()\n",
    "            if \"algorithm\" not in df.columns:\n",
    "                df[\"algorithm\"] = algo\n",
    "            else:\n",
    "                # ensure the algorithm column actually says the dict key\n",
    "                df[\"algorithm\"] = algo\n",
    "            parts.append(df)\n",
    "        return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    elif isinstance(per_img, pd.DataFrame):\n",
    "        df = per_img.copy()\n",
    "        if \"algorithm\" not in df.columns:\n",
    "            df[\"algorithm\"] = \"model\"\n",
    "        return df\n",
    "    else:\n",
    "        raise TypeError(\"per_img must be a dict[str, DataFrame] or a DataFrame.\")\n",
    "\n",
    "def _infer_ap_cols(df):\n",
    "    \"\"\"\n",
    "    Find AP columns named like 'AP@0.50', 'AP@0.55', ...\n",
    "    Return (thr_array, ordered_ap_cols).\n",
    "    \"\"\"\n",
    "    ap_cols = [c for c in df.columns if re.match(r\"^AP@\\d\\.\\d{2}$\", c)]\n",
    "    if not ap_cols:\n",
    "        raise ValueError(\"No AP@xx.xx columns found in per-image table.\")\n",
    "    thr = np.array([float(c.split(\"@\")[1]) for c in ap_cols], dtype=float)\n",
    "    order = np.argsort(thr)\n",
    "    thr = thr[order]\n",
    "    ap_cols = [ap_cols[i] for i in order]\n",
    "    return thr, ap_cols\n",
    "\n",
    "\n",
    "# ---------- PLOTS ----------\n",
    "def plot_ap_curves_multi(\n",
    "    per_img,\n",
    "    out_png: Path = None,  # kept for backward-compat\n",
    "    title: str = \"Nuclei benchmark â€” overall\",\n",
    "    dpi: int = 300,\n",
    "    out_base: Path | None = None,  # NEW: if provided, saves both PDF + PNG with this base\n",
    "):\n",
    "    \"\"\"\n",
    "    Build AP curves per algorithm and plot multiple lines.\n",
    "    Also compute mAP (mean over thresholds) per algorithm.\n",
    "    Returns (curve_df, mAP_series).\n",
    "    \"\"\"\n",
    "    _apply_science_style()\n",
    "\n",
    "    df = _as_perimg_df(per_img)\n",
    "    if df.empty:\n",
    "        print(\"No matched GT/prediction pairs. Check filename pairing (gt_strip/pred_strip).\")\n",
    "        return None, None\n",
    "\n",
    "    thr, ap_cols = _infer_ap_cols(df)\n",
    "\n",
    "    # Safety check: ensure all AP columns exist\n",
    "    missing = [c for c in ap_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing AP columns: {missing}\")\n",
    "\n",
    "    # Mean across images per algorithm -> AP curve matrix\n",
    "    curve = df.groupby(\"algorithm\", sort=True)[ap_cols].mean()\n",
    "    mAP = curve.mean(axis=1)\n",
    "\n",
    "    # Sort algorithms by descending mAP (legend will follow plotting order)\n",
    "    sorted_mAP = mAP.sort_values(ascending=False)\n",
    "    sorted_curve = curve.loc[sorted_mAP.index]\n",
    "\n",
    "    # Plot curves\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # Draw in sorted order so legend is ranked high â†’ low by mAP\n",
    "    for algo, row in sorted_curve.iterrows():\n",
    "        ax.plot(\n",
    "            thr, row.values,\n",
    "            marker=\"o\", linewidth=2,\n",
    "            label=f\"{algo} (mAP={mAP[algo]:.2f})\"\n",
    "        )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"IoU Threshold\")\n",
    "    ax.set_ylabel(\"Average Precision(AP)\")\n",
    "    ax.set_xlim(thr[0], thr[-1])\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(frameon=False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Saving logic:\n",
    "    if out_base is not None:\n",
    "        _save_both(fig, Path(out_base), dpi=dpi, transparent=True)\n",
    "    elif out_png is not None:\n",
    "        # Back-compat: if only PNG path was given, save PNG AND a twin PDF\n",
    "        base = Path(out_png).with_suffix(\"\")  # remove .png if present\n",
    "        _save_both(fig, base, dpi=dpi, transparent=True)\n",
    "\n",
    "    plt.show()\n",
    "    return curve, mAP\n",
    "\n",
    "\n",
    "def plot_map_bars(\n",
    "    mAP,\n",
    "    out_png: Path = None,  # kept for backward-compat\n",
    "    dpi: int = 300,\n",
    "    title: str = \"mAP (mean over IoU thresholds)\",\n",
    "    out_base: Path | None = None,  # NEW: if provided, saves both PDF + PNG with this base\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a simple bar chart for per-algorithm mAP.\n",
    "    Legend not needed; bars are labeled by algo on x-axis.\n",
    "    \"\"\"\n",
    "    _apply_science_style()\n",
    "\n",
    "    if mAP is None or len(mAP) == 0:\n",
    "        print(\"Empty mAP; nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    mAP = mAP.sort_values(ascending=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    mAP.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_ylabel(\"mAP\")\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Saving logic:\n",
    "    if out_base is not None:\n",
    "        _save_both(fig, Path(out_base), dpi=dpi, transparent=True)\n",
    "    elif out_png is not None:\n",
    "        base = Path(out_png).with_suffix(\"\")\n",
    "        _save_both(fig, base, dpi=dpi, transparent=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e84be-535b-47b0-bb52-1bd3411f82f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T01:04:41.545677Z",
     "start_time": "2025-09-16T01:04:40.458810Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# per_img_nuc can be a dict of DataFrames OR a single DataFrame.\n",
    "curve, mAP = plot_ap_curves_multi(\n",
    "    per_img=per_img_nuc,\n",
    "    out_png=Path(\"figs/nuclei_overall_ap.png\"),\n",
    "    title=\"Nuclei benchmark\",\n",
    "    dpi=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5750ad0-220e-4350-8f9b-ca7ef2224d39",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Full script: same-height side-by-side AP curves (Cell vs. Nuclei) with Arial (or fallbacks)\n",
    "from pathlib import Path\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# =========================\n",
    "# ===== FONT HANDLING =====\n",
    "# =========================\n",
    "# Where to store downloaded fonts (if needed)\n",
    "FONT_DIR = Path(\"/ihome/jbwang/liy121/fonts\")          # ä½ è¦â€œç›´æŽ¥ä¸‹è½½åˆ°è·¯å¾„â€çš„ç›®å½•ï¼Œå¯æ”¹æˆç»å¯¹è·¯å¾„\n",
    "AUTO_DOWNLOAD_ARIMO = True          # è‹¥æ—  Arialï¼Œè‡ªåŠ¨ä¸‹è½½ Arimoï¼ˆArial å…¼å®¹ï¼‰åˆ° FONT_DIR\n",
    "ARIMO_TTFS = {\n",
    "    \"Arimo-Regular.ttf\": \"https://github.com/googlefonts/Arimo/raw/main/fonts/ttf/Arimo-Regular.ttf\",\n",
    "    \"Arimo-Bold.ttf\": \"https://github.com/googlefonts/Arimo/raw/main/fonts/ttf/Arimo-Bold.ttf\",\n",
    "    \"Arimo-Italic.ttf\": \"https://github.com/googlefonts/Arimo/raw/main/fonts/ttf/Arimo-Italic.ttf\",\n",
    "    \"Arimo-BoldItalic.ttf\": \"https://github.com/googlefonts/Arimo/raw/main/fonts/ttf/Arimo-BoldItalic.ttf\",\n",
    "}\n",
    "\n",
    "def _font_installed(face_name: str) -> bool:\n",
    "    try:\n",
    "        return any(f.name == face_name for f in fm.fontManager.ttflist)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _download_arimo(dst_dir: Path) -> bool:\n",
    "    \"\"\"Download Arimo TTFs to dst_dir; return True if at least one file saved.\"\"\"\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ok = False\n",
    "    for fname, url in ARIMO_TTFS.items():\n",
    "        out = dst_dir / fname\n",
    "        if out.exists() and out.stat().st_size > 0:\n",
    "            ok = True\n",
    "            continue\n",
    "        try:\n",
    "            with urllib.request.urlopen(url, timeout=30) as r:\n",
    "                data = r.read()\n",
    "            out.write_bytes(data)\n",
    "            ok = True\n",
    "        except Exception as e:\n",
    "            # ä¸ä¸­æ–­ï¼Œå°½åŠ›è€Œä¸º\n",
    "            print(f\"[font] Failed to fetch {fname}: {e}\", file=sys.stderr)\n",
    "    return ok\n",
    "\n",
    "def _register_dir_fonts(dir_path: Path):\n",
    "    \"\"\"Register all .ttf/.otf in dir_path with Matplotlib.\"\"\"\n",
    "    if not dir_path.exists():\n",
    "        return\n",
    "    for p in dir_path.glob(\"*.ttf\"):\n",
    "        try:\n",
    "            fm.fontManager.addfont(str(p))\n",
    "        except Exception:\n",
    "            pass\n",
    "    for p in dir_path.glob(\"*.otf\"):\n",
    "        try:\n",
    "            fm.fontManager.addfont(str(p))\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        fm._rebuild()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def ensure_arial_or_fallback():\n",
    "    \"\"\"\n",
    "    Priority:\n",
    "      1) Arial (if installed)\n",
    "      2) Liberation Sans (ä½ æœºå™¨å·²æœ‰)\n",
    "      3) Arimo (è‹¥å…è®¸åˆ™è‡ªåŠ¨ä¸‹è½½æ³¨å†Œåˆ° ./fonts)\n",
    "      4) DejaVu Sans / Nimbus Sans / Droid Sans\n",
    "    Returns: the first available name actually used.\n",
    "    \"\"\"\n",
    "    # å°è¯•å…ˆæ³¨å†Œ FONT_DIR ä¸­å¯èƒ½å·²æœ‰çš„å­—ä½“\n",
    "    _register_dir_fonts(FONT_DIR)\n",
    "\n",
    "    if _font_installed(\"Arial\"):\n",
    "        return \"Arial\"\n",
    "\n",
    "    if _font_installed(\"Liberation Sans\"):\n",
    "        return \"Liberation Sans\"\n",
    "\n",
    "    # å°è¯• Arimoï¼šè‹¥æœªå®‰è£…ä¸”å…è®¸ä¸‹è½½ï¼Œåˆ™ä¸‹è½½å¹¶æ³¨å†Œ\n",
    "    if not _font_installed(\"Arimo\") and AUTO_DOWNLOAD_ARIMO:\n",
    "        print(f\"[font] Arial not found. Downloading Arimo to {FONT_DIR.resolve()} ...\")\n",
    "        if _download_arimo(FONT_DIR):\n",
    "            _register_dir_fonts(FONT_DIR)\n",
    "\n",
    "    if _font_installed(\"Arimo\"):\n",
    "        return \"Arimo\"\n",
    "\n",
    "    # å…œåº•ï¼šè¿™äº›ä¸€èˆ¬éšç³»ç»Ÿ/Matplotlib é™„å¸¦\n",
    "    for name in [\"DejaVu Sans\", \"Nimbus Sans\", \"Droid Sans\", \"Liberation Sans Narrow\"]:\n",
    "        if _font_installed(name):\n",
    "            return name\n",
    "\n",
    "    # æœ€åŽå…œåº•ï¼šä½¿ç”¨ Matplotlib é»˜è®¤\n",
    "    return \"sans-serif\"\n",
    "\n",
    "def apply_pub_style():\n",
    "    \"\"\"Apply publication-like style and set font family order with Arial-first semantics.\"\"\"\n",
    "    # Optional SciencePlots\n",
    "    try:\n",
    "        plt.style.use(['science', 'no-latex'])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    chosen = ensure_arial_or_fallback()\n",
    "\n",
    "    # æž„å»º font.sans-serif ä¼˜å…ˆçº§åˆ—è¡¨ï¼ˆå°† chosen æ”¾åœ¨æœ€å‰ï¼‰\n",
    "    preferred = [chosen, \"Arial\", \"Liberation Sans\", \"Arimo\", \"DejaVu Sans\", \"Nimbus Sans\", \"Droid Sans\"]\n",
    "    existing = list(mpl.rcParams.get(\"font.sans-serif\", []))\n",
    "    ordered = []\n",
    "    for f in preferred + existing:\n",
    "        if f not in ordered:\n",
    "            ordered.append(f)\n",
    "\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": ordered,\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"legend.fontsize\": 9,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.3,\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.dpi\": 120,\n",
    "        \"mathtext.fontset\": \"dejavusans\",\n",
    "    })\n",
    "\n",
    "    print(f\"[font] Using: {chosen}\")\n",
    "\n",
    "# =========================\n",
    "# ====== PLOT HELPERS =====\n",
    "# =========================\n",
    "def as_perimg_df(per_img):\n",
    "    \"\"\"\n",
    "    per_img å¯ä¸º:\n",
    "      - dict: {algo_name: per-image DataFrame}\n",
    "      - DataFrame: å«æˆ–ä¸å« 'algorithm' åˆ—\n",
    "    è¿”å›žåˆå¹¶åŽçš„ DataFrameï¼Œä¿è¯å« 'algorithm' åˆ—ã€‚\n",
    "    \"\"\"\n",
    "    if isinstance(per_img, dict):\n",
    "        parts = []\n",
    "        for algo, df in per_img.items():\n",
    "            if df is None or len(df) == 0:\n",
    "                continue\n",
    "            df = df.copy()\n",
    "            df[\"algorithm\"] = algo\n",
    "            parts.append(df)\n",
    "        return pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    elif isinstance(per_img, pd.DataFrame):\n",
    "        df = per_img.copy()\n",
    "        if \"algorithm\" not in df.columns:\n",
    "            df[\"algorithm\"] = \"model\"\n",
    "        return df\n",
    "    else:\n",
    "        raise TypeError(\"per_img must be dict[str, DataFrame] or DataFrame.\")\n",
    "\n",
    "def infer_ap_cols(df: pd.DataFrame):\n",
    "    \"\"\"æ£€æµ‹ 'AP@0.50' è¿™ç±»åˆ—ï¼›è¿”å›ž (thr_array, ordered_cols)ã€‚\"\"\"\n",
    "    ap_cols = [c for c in df.columns if re.match(r\"^AP@\\d\\.\\d{2}$\", c)]\n",
    "    if not ap_cols:\n",
    "        raise ValueError(\"No AP@xx.xx columns found.\")\n",
    "    thr = np.array([float(c.split(\"@\")[1]) for c in ap_cols], dtype=float)\n",
    "    order = np.argsort(thr)\n",
    "    thr = thr[order]\n",
    "    ap_cols = [ap_cols[i] for i in order]\n",
    "    return thr, ap_cols\n",
    "\n",
    "def ap_curve_and_map(per_img):\n",
    "    \"\"\"\n",
    "    è®¡ç®—ï¼š\n",
    "      - curve: æ¯ç®—æ³•æ¯ IoU çš„ AP å‡å€¼ï¼ˆDataFrame: algo x thresholdsï¼‰\n",
    "      - mAP:   æ¯ç®—æ³•åœ¨é˜ˆå€¼ä¸Šçš„å¹³å‡ï¼ˆSeriesï¼‰\n",
    "      - thr:   IoU é˜ˆå€¼æ•°ç»„\n",
    "    \"\"\"\n",
    "    df = as_perimg_df(per_img)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), pd.Series(dtype=float), np.array([])\n",
    "    thr, ap_cols = infer_ap_cols(df)\n",
    "    curve = df.groupby(\"algorithm\", sort=True)[ap_cols].mean()\n",
    "    mAP = curve.mean(axis=1)\n",
    "    return curve, mAP, thr\n",
    "\n",
    "def save_both(fig: plt.Figure, base: Path, dpi: int = 400, transparent: bool = True):\n",
    "    base = Path(base)\n",
    "    if base.suffix:\n",
    "        base = base.with_suffix(\"\")\n",
    "    base.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pdf = base.with_suffix(\".pdf\")\n",
    "    png = base.with_suffix(\".png\")\n",
    "    fig.savefig(pdf, format=\"pdf\", transparent=transparent)\n",
    "    fig.savefig(png, format=\"png\", dpi=dpi, transparent=transparent)\n",
    "    print(f\"Saved:\\n  {pdf}\\n  {png}\")\n",
    "\n",
    "def plot_two_panels_same_axes(\n",
    "    per_img_cell,\n",
    "    per_img_nuc,\n",
    "    title_left=\"Cell benchmark â€” overall\",\n",
    "    title_right=\"Nuclei benchmark â€” overall\",\n",
    "    out_base=\"figs/ap_cell_vs_nuclei_side_by_side\",\n",
    "    figsize=(10, 4.0),\n",
    "    dpi=400,\n",
    "):\n",
    "    \"\"\"å¹¶æŽ’ã€åŒåæ ‡èŒƒå›´ AP æ›²çº¿ï¼Œä¿å­˜ PDF+PNGã€‚\"\"\"\n",
    "    apply_pub_style()\n",
    "\n",
    "    curve_c, mAP_c, thr_c = ap_curve_and_map(per_img_cell)\n",
    "    curve_n, mAP_n, thr_n = ap_curve_and_map(per_img_nuc)\n",
    "\n",
    "    if curve_c.empty and curve_n.empty:\n",
    "        raise ValueError(\"Both cell and nuclei inputs are empty.\")\n",
    "    if curve_c.empty:\n",
    "        print(\"Warning: cell data empty â€” plotting nuclei only.\")\n",
    "    if curve_n.empty:\n",
    "        print(\"Warning: nuclei data empty â€” plotting cell only.\")\n",
    "\n",
    "    # ç»Ÿä¸€åæ ‡è½´èŒƒå›´/åˆ»åº¦\n",
    "    shared_thr = np.round(np.arange(0.50, 0.96, 0.05), 2)  # 0.50â€“0.95 step 0.05\n",
    "    x_min, x_max = shared_thr[0], shared_thr[-1]\n",
    "    y_min, y_max = 0.0, 1.0\n",
    "\n",
    "    def reindex_curve(curve):\n",
    "        if curve.empty:\n",
    "            return curve\n",
    "        target = [f\"AP@{t:.2f}\" for t in shared_thr]\n",
    "        for col in target:\n",
    "            if col not in curve.columns:\n",
    "                curve[col] = np.nan\n",
    "        return curve[target]\n",
    "\n",
    "    curve_c = reindex_curve(curve_c)\n",
    "    curve_n = reindex_curve(curve_n)\n",
    "\n",
    "    if not curve_c.empty:\n",
    "        mAP_c = curve_c.mean(axis=1)\n",
    "        curve_c = curve_c.loc[mAP_c.sort_values(ascending=False).index]\n",
    "    if not curve_n.empty:\n",
    "        mAP_n = curve_n.mean(axis=1)\n",
    "        curve_n = curve_n.loc[mAP_n.sort_values(ascending=False).index]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, sharey=True)\n",
    "    axR, axL = axes\n",
    "\n",
    "    # å·¦å›¾ï¼šCell\n",
    "    if not curve_c.empty:\n",
    "        for algo, row in curve_c.iterrows():\n",
    "            axL.plot(shared_thr, row.values, marker=\"o\", linewidth=2,\n",
    "                     label=f\"{algo} (mAP={mAP_c[algo]:.2f})\")\n",
    "    axL.set_title(title_left)\n",
    "    axL.set_xlabel(\"IoU Threshold\")\n",
    "    axL.set_ylabel(\"Average Precision\")\n",
    "    axL.set_xlim(x_min, x_max)\n",
    "    axL.set_ylim(y_min, y_max)\n",
    "    axL.minorticks_on()\n",
    "    axL.grid(alpha=0.3)\n",
    "    if not curve_c.empty:\n",
    "        axL.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    # å³å›¾ï¼šNuclei\n",
    "    if not curve_n.empty:\n",
    "        for algo, row in curve_n.iterrows():\n",
    "            axR.plot(shared_thr, row.values, marker=\"o\", linewidth=2,\n",
    "                     label=f\"{algo} (mAP={mAP_n[algo]:.2f})\")\n",
    "    axR.set_title(title_right)\n",
    "    axR.set_xlabel(\"IoU Threshold\")\n",
    "    axR.set_xlim(x_min, x_max)\n",
    "    axR.set_ylim(y_min, y_max)\n",
    "    axR.minorticks_on()\n",
    "    axR.grid(alpha=0.3)\n",
    "    if not curve_n.empty:\n",
    "        axR.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    # ç»Ÿä¸€ x åˆ»åº¦ä¸Žæ ‡ç­¾\n",
    "    axL.set_xticks(shared_thr); axR.set_xticks(shared_thr)\n",
    "    xtlabs = [f\"{t:.2f}\" for t in shared_thr]\n",
    "    axL.set_xticklabels(xtlabs); axR.set_xticklabels(xtlabs)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    save_both(fig, Path(out_base), dpi=dpi, transparent=True)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# =========================\n",
    "# ========= RUN ===========\n",
    "# éœ€è¦ä½ çŽ¯å¢ƒé‡Œå·²æœ‰å˜é‡ï¼šper_img_cytoï¼ˆç»†èƒžï¼‰ï¼Œper_img_nucï¼ˆæ ¸ï¼‰\n",
    "# ç›´æŽ¥è¿è¡Œä¸‹è¡Œè°ƒç”¨ï¼ˆå¯æŒ‰éœ€æ”¹ä¿å­˜è·¯å¾„å’Œæ ‡é¢˜ï¼‰ï¼š\n",
    "fig = plot_two_panels_same_axes(\n",
    "    per_img_cell=per_img_cyto,\n",
    "    per_img_nuc=per_img_nuc,\n",
    "    title_left=\"Cell benchmark\",\n",
    "    title_right=\"Nuclei benchmark\",\n",
    "    out_base=\"figs/ap_cell_vs_nuclei_side_by_side\",\n",
    "    figsize=(10, 4.0),\n",
    "    dpi=400,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a988ff7-8ad3-42ab-971e-d960f522e0d6",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# â€”â€”â€” Nuclei benchmark: AP-vs-IoU curves per group (facet plot) â€”â€”â€”\n",
    "# Legend ranked highâ†’low by mAP, \"sci\" style, and save to PDF/PNG.\n",
    "# All comments are in ENGLISH.\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- STYLE: prefer SciencePlots if available ----------\n",
    "# Try to use the 'science' style (from SciencePlots). If not installed, fall back\n",
    "# to a clean Matplotlib configuration that looks \"scientific\".\n",
    "try:\n",
    "    plt.style.use(['science', 'no-latex'])  # requires 'SciencePlots' pip package\n",
    "except Exception:\n",
    "    # Fallback: serif font, tighter layout, inward ticks, minor ticks, thinner spines.\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.size\": 10,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.3,\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"figure.dpi\": 120,\n",
    "    })\n",
    "\n",
    "# ---------- INPUTS / SANITY CHECKS ----------\n",
    "if 'thr' not in globals():\n",
    "    thr = np.arange(0.50, 0.96, 0.05)\n",
    "if 'ap_cols' not in globals():\n",
    "    ap_cols = [f\"AP@{t:.2f}\" for t in thr]\n",
    "\n",
    "groups = {\n",
    "    \"OLIG2\": r\"OLIG2\",\n",
    "    \"NEUN\":  r\"NEUN\",\n",
    "    \"IBA1\":  r\"IBA1\",\n",
    "    \"GFAP\":  r\"GFAP\",\n",
    "    \"PECAM\": r\"PECAM\",\n",
    "}\n",
    "\n",
    "# Require a DataFrame named `per_img_nuc` with columns:\n",
    "# ['base', 'algorithm', ... AP@0.50 ... AP@0.95 ...]\n",
    "if per_img_nuc.empty:\n",
    "    raise ValueError(\"per_img_nuc is empty (no matched GT/pred pairs). Check pairing rules.\")\n",
    "\n",
    "missing_cols = [c for c in ap_cols if c not in per_img_nuc.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing AP columns: {missing_cols}. \"\n",
    "                     f\"Ensure ap_thresholds={tuple(np.round(thr, 2))}.\")\n",
    "\n",
    "if \"algorithm\" not in per_img_nuc.columns:\n",
    "    raise ValueError(\"Missing required column: 'algorithm'.\")\n",
    "\n",
    "if \"base\" not in per_img_nuc.columns:\n",
    "    raise ValueError(\"Missing required column: 'base' used for grouping by panel names.\")\n",
    "\n",
    "# ---------- LAYOUT ----------\n",
    "ncols = 3\n",
    "nrows = math.ceil(len(groups) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(12, 7), squeeze=False)\n",
    "\n",
    "# ---------- PLOTTING ----------\n",
    "for ax, (gname, pattern) in zip(axes.ravel(), groups.items()):\n",
    "    # Subset images belonging to this panel/group\n",
    "    sub = per_img_nuc[per_img_nuc[\"base\"].str.contains(pattern, case=False, regex=True, na=False)]\n",
    "\n",
    "    if sub.empty:\n",
    "        ax.set_title(f\"Nuclei: {gname} (no images)\")\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    # Mean AP curve across images for each algorithm\n",
    "    grp_curve = sub.groupby(\"algorithm\", sort=False)[ap_cols].mean()\n",
    "\n",
    "    # mAP = mean across IoU thresholds\n",
    "    grp_mAP = grp_curve.mean(axis=1)\n",
    "\n",
    "    # Keep line handles by algorithm so we can sort legend independently of plot order\n",
    "    line_by_algo = {}\n",
    "\n",
    "    # Plot each algorithm's AP-vs-IoU curve\n",
    "    for algo, row in grp_curve.iterrows():\n",
    "        ln, = ax.plot(\n",
    "            thr, row.values,\n",
    "            marker='o', linewidth=2,\n",
    "            label=f\"{algo} (mAP={grp_mAP[algo]:.02f})\"\n",
    "        )\n",
    "        line_by_algo[algo] = ln\n",
    "\n",
    "    # Axes cosmetics\n",
    "    ax.set_title(f\"Nuclei: {gname}\")\n",
    "    ax.set_xlabel(\"IoU Threshold\")\n",
    "    ax.set_ylabel(\"Average Precision\")\n",
    "    ax.set_xlim(thr.min(), thr.max())\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    # ---------- LEGEND ranked highâ†’low by mAP ----------\n",
    "    # Sort algorithms by descending mAP and build legend in that order.\n",
    "    sorted_algos = sorted(grp_mAP.index, key=lambda k: grp_mAP[k], reverse=True)\n",
    "    handles = [line_by_algo[a] for a in sorted_algos]\n",
    "    labels  = [f\"{a} (mAP={grp_mAP[a]:.02f})\" for a in sorted_algos]\n",
    "    ax.legend(handles, labels, fontsize=8, frameon=False)\n",
    "\n",
    "# Hide any unused axes (if groups < nrows*ncols)\n",
    "for ax in axes.ravel()[len(groups):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# ---------- SAVE FIGURES ----------\n",
    "# Pay attention to the file path: set your desired output directory here.\n",
    "out_dir = \"./figs\"  # change if you want a different path\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "pdf_path = os.path.join(out_dir, \"nuclei_AP_vs_IoU_by_group.pdf\")\n",
    "png_path = os.path.join(out_dir, \"nuclei_AP_vs_IoU_by_group.png\")\n",
    "\n",
    "# Save high-quality vector PDF and a high-DPI PNG\n",
    "fig.savefig(pdf_path, format=\"pdf\", transparent=True)\n",
    "fig.savefig(png_path, format=\"png\", dpi=300, transparent=True)\n",
    "\n",
    "print(f\"Saved:\\n  {pdf_path}\\n  {png_path}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db595749-4460-41f0-afa5-1f9d5808f2a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Oval shape Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c8558fd90934d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATASET_DIR = Path(\"00_dataset\")\n",
    "OUT_DIR = Path(\"overlay_outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "NUC_GT_SUFFIX = \"_ovaldapimultimask.npy\"\n",
    "DAPI_SUFFIXES = (\".tiff\", \".tif\")\n",
    "\n",
    "\n",
    "def stack_to_label(mask_stack: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a binary mask stack (N, H, W) into a single labeled mask (H, W).\n",
    "    Each nucleus gets a unique integer ID.\n",
    "    \"\"\"\n",
    "    if mask_stack.ndim == 3:\n",
    "        label_img = np.zeros(mask_stack.shape[1:], dtype=np.int32)\n",
    "        for i, mask in enumerate(mask_stack, 1):\n",
    "            label_img[mask > 0] = i\n",
    "        return label_img\n",
    "    return mask_stack  # already label map\n",
    "\n",
    "\n",
    "def save_overlay(dapi_path: Path, mask_path: Path, out_dir: Path, alpha=0.4):\n",
    "    dapi_img = tiff.imread(dapi_path)\n",
    "    mask_data = np.load(mask_path)\n",
    "\n",
    "    # convert if it's a stack\n",
    "    masks = stack_to_label(mask_data)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(dapi_img, cmap=\"gray\")\n",
    "    plt.imshow(masks, cmap=\"nipy_spectral\", alpha=alpha)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{dapi_path.stem}\")\n",
    "\n",
    "    # save to OUT_DIR\n",
    "    out_path = out_dir / f\"{dapi_path.stem}_overlay.png\"\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\", dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[SAVED] {out_path}\")\n",
    "\n",
    "\n",
    "def find_and_save_all(dataset_dir: Path, out_dir: Path):\n",
    "    for mask_path in dataset_dir.rglob(f\"*{NUC_GT_SUFFIX}\"):\n",
    "        base = mask_path.name.replace(NUC_GT_SUFFIX, \"\")\n",
    "        dapi_path = None\n",
    "        for suf in DAPI_SUFFIXES:\n",
    "            candidate = mask_path.parent / f\"{base}{suf}\"\n",
    "            if candidate.exists():\n",
    "                dapi_path = candidate\n",
    "                break\n",
    "\n",
    "        if dapi_path is None:\n",
    "            print(f\"[WARN] No DAPI found for {mask_path.name}\")\n",
    "            continue\n",
    "\n",
    "        save_overlay(dapi_path, mask_path, out_dir)\n",
    "\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "find_and_save_all(DATASET_DIR, OUT_DIR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ca0cd6239efeeec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Evaluation on Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fcea4-8ade-4698-9bc2-2d7c0ffc1f50",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259aeb8ecc74e07",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Verbose driver for evaluating all cyto-refined folders.\n",
    "Prints dataset stats, thresholds, per-algorithm file counts, runtime,\n",
    "and top rankings by AP@0.50 and IoU@0.50.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluation_tasks import evaluate_cell_benchmark\n",
    "\n",
    "# ---- Paths ----\n",
    "GT_DIR   = Path(\"/ihome/jbwang/liy121/ifimage/00_dataset\")\n",
    "OUT_ROOT = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/refilter_experiment_oct7\")\n",
    "REF_ROOT  = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/refilter_experiment_oct7\")\n",
    "RAW_DIR   = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction\")\n",
    "SAVE_DIR  = REF_ROOT / \"_eval_results_1435\"\n",
    "\n",
    "# ---- Collect algorithms ----\n",
    "preds = {p.name: p for p in REF_ROOT.iterdir() if p.is_dir()}  # all refined\n",
    "if RAW_DIR.exists():\n",
    "    preds[\"cellpose_cyto_raw\"] = RAW_DIR                       # also include raw\n",
    "\n",
    "print(f\"[info] total algorithms: {len(preds)}\")\n",
    "\n",
    "# ---- Thresholds (must include 0.50) ----\n",
    "thr = np.arange(0.50, 0.96, 0.05)\n",
    "ap_thresholds = tuple(np.round(thr, 2))\n",
    "\n",
    "# ---- Pre-run report ----\n",
    "gt_files = sorted(GT_DIR.glob(\"*_cellbodies.npy\"))\n",
    "print(f\"[info] #GT files: {len(gt_files)}  dir: {GT_DIR}\")\n",
    "print(f\"[info] #algorithms to evaluate: {len(preds)}  root: {OUT_ROOT}\")\n",
    "for name in sorted(preds):\n",
    "    n_pred = len(list(preds[name].glob(\"*.npy\")))\n",
    "    print(f\"  - {name:>40s} : {n_pred:5d} prediction files\")\n",
    "\n",
    "print(f\"[info] IoU thresholds for AP: {ap_thresholds}\")\n",
    "planned_workers = os.cpu_count() or 1\n",
    "print(f\"[info] Planned processes (if max_workers=None): {planned_workers}\")\n",
    "\n",
    "if len(preds) == 0:\n",
    "    raise SystemExit(\"[fatal] No algorithm subfolders found. Check OUT_ROOT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6214af9-86dd-46f0-8aaa-e6d2203c7e42",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "per_img, summ = evaluate_cell_benchmark(\n",
    "    dataset_dir=GT_DIR,\n",
    "    cyto_pred_dirs=preds,\n",
    "    ap_thresholds=ap_thresholds,\n",
    "    boundary_scales=(1.0,),\n",
    "    max_workers=2,\n",
    "    out_dir=SAVE_DIR,\n",
    "    run_id=\"refilter_grid\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"per-image:\", (SAVE_DIR / \"ALL__refilter_grid__per_image.csv\"))\n",
    "print(\"summary :\", (SAVE_DIR / \"ALL__refilter_grid__summary.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7f759-749c-4c4f-b9d2-ee384bacf549",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---- Post-run sanity + rankings ----\n",
    "if per_img is None or len(per_img) == 0:\n",
    "    raise SystemExit(\"[warn] No per-image results produced. Likely no pairs matched.\")\n",
    "\n",
    "# Pair counts per algorithm\n",
    "pair_counts = per_img.groupby(\"algorithm\").size().sort_values(ascending=False)\n",
    "print(\"\\n[info] #paired images per algorithm:\")\n",
    "for algo, cnt in pair_counts.items():\n",
    "    print(f\"  - {algo:>40s} : {cnt:5d}\")\n",
    "\n",
    "has_ap = \"AP@0.50\" in per_img.columns\n",
    "has_iou = \"IoU@0.50\" in per_img.columns\n",
    "\n",
    "has_map = \"mAP\" in per_img.columns\n",
    "if has_ap:\n",
    "    rank_ap = per_img.groupby(\"algorithm\")[\"AP@0.50\"].mean().sort_values(ascending=False)\n",
    "    print(\"\\n[rank] Mean AP@0.50 (Top 10):\")\n",
    "    for algo, v in rank_ap.head(10).items():\n",
    "        print(f\"  - {algo:>40s} : {v:.4f}\")\n",
    "else:\n",
    "    print(\"\\n[warn] Column AP@0.50 not found. Ensure evaluation_tasks.py adds it.\")\n",
    "\n",
    "if has_iou:\n",
    "    rank_iou = per_img.groupby(\"algorithm\")[\"IoU@0.50\"].mean().sort_values(ascending=False)\n",
    "    print(\"\\n[rank] Mean IoU@0.50 (Top 10):\")\n",
    "    for algo, v in rank_iou.head(10).items():\n",
    "        print(f\"  - {algo:>40s} : {v:.4f}\")\n",
    "else:\n",
    "    print(\"\\n[warn] Column IoU@0.50 not found. Ensure evaluation_tasks.py adds it.\")\n",
    "    \n",
    "if has_iou:\n",
    "    rank_iou = per_img.groupby(\"algorithm\")[\"mAP\"].mean().sort_values(ascending=False)\n",
    "    print(\"\\n[rank] Mean mAP (Top 10):\")\n",
    "    for algo, v in rank_iou.head(10).items():\n",
    "        print(f\"  - {algo:>40s} : {v:.4f}\")\n",
    "else:\n",
    "    print(\"\\n[warn] Column IoU@0.50 not found. Ensure evaluation_tasks.py adds it.\")\n",
    "    \n",
    "    \n",
    "# Completeness summary\n",
    "total_algos = per_img[\"algorithm\"].nunique()\n",
    "print(f\"\\n[info] Total algorithms: {total_algos} | \"\n",
    "      f\"AP@0.50 available: {0 if not has_ap else rank_ap.size} | \"\n",
    "      f\"IoU@0.50 available: {0 if not has_iou else rank_iou.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6fa83-c9a8-4847-84e6-599b584171db",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- FIXED ROOTS ----\n",
    "CYTO_DIR = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction\")\n",
    "OUT_ROOT = CYTO_DIR.parent / \"refilter_experiment_oct7\"\n",
    "GT_DIR   = Path(\"/ihome/jbwang/liy121/ifimage/00_dataset\")\n",
    "\n",
    "BASE_FILE = \"olig2_12790_pred_cyto.npy\"  # same name as in cyto_prediction\n",
    "\n",
    "EXPERIMENT_SLUGS = [\n",
    "    \"feat-mean_thr-otsu_area-100_gate-off\",\n",
    "]\n",
    "\n",
    "# ---- HELPERS ----\n",
    "def core_from_pred_filename(fname: str) -> str:\n",
    "    return Path(fname).stem.replace(\"_pred_cyto\", \"\")\n",
    "\n",
    "def load_mask(path: Path) -> np.ndarray:\n",
    "    if path.suffix.lower() == \".npy\":\n",
    "        return np.load(path)\n",
    "    return np.squeeze(tiff.imread(str(path)))\n",
    "\n",
    "def find_gt_cellbodies(gt_root: Path, core: str) -> np.ndarray:\n",
    "    pats = [f\"{core}_cellbodies.npy\", f\"{core}_cellbodies.tif\", f\"{core}_cellbodies.tiff\"]\n",
    "    for p in pats:\n",
    "        for f in gt_root.glob(p):\n",
    "            return load_mask(f)\n",
    "    raise FileNotFoundError(f\"GT not found for {core}_cellbodies under {gt_root}\")\n",
    "\n",
    "# ---- LOAD ----\n",
    "cyto_path = CYTO_DIR / BASE_FILE\n",
    "assert cyto_path.exists(), f\"missing {cyto_path}\"\n",
    "core = core_from_pred_filename(BASE_FILE)\n",
    "\n",
    "gt = find_gt_cellbodies(GT_DIR, core)\n",
    "orig_pred = load_mask(cyto_path)\n",
    "\n",
    "masks = [orig_pred]\n",
    "names = [\"Original_pred_cyto\"]\n",
    "\n",
    "for slug in EXPERIMENT_SLUGS:\n",
    "    p = OUT_ROOT / slug / BASE_FILE\n",
    "    assert p.exists(), f\"missing {p}\"\n",
    "    masks.append(load_mask(p))\n",
    "    names.append(slug)\n",
    "\n",
    "# ---- PLOT ----\n",
    "fig, axes = plt.subplots(1, len(masks)+1, figsize=(4*(len(masks)+1), 4))\n",
    "axes[0].imshow(gt, cmap=\"tab20\")\n",
    "axes[0].set_title(\"GT: _cellbodies\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "for i, (m, n) in enumerate(zip(masks, names), 1):\n",
    "    axes[i].imshow(m, cmap=\"tab20\")\n",
    "    axes[i].set_title(n)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d09f7-c7f5-441d-b0af-56dfa633f24f",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- FIXED ROOTS ----\n",
    "CYTO_DIR = Path(\"/ihome/jbwang/liy121/ifimage/01_cellpose_benchmark/cyto_prediction\")\n",
    "OUT_ROOT = CYTO_DIR.parent / \"refilter_experiment_oct7\"\n",
    "GT_DIR   = Path(\"/ihome/jbwang/liy121/ifimage/00_dataset\")\n",
    "\n",
    "BASE_FILE = \"olig2_12790_pred_cyto.npy\"  # same name as in cyto_prediction\n",
    "\n",
    "EXPERIMENT_SLUGS = [\n",
    "    \"feat-mean_thr-otsu_area-100_gate-off\",\n",
    "]\n",
    "\n",
    "# ---- HELPERS ----\n",
    "def core_from_pred_filename(fname: str) -> str:\n",
    "    return Path(fname).stem.replace(\"_pred_cyto\", \"\")\n",
    "\n",
    "def load_mask(path: Path) -> np.ndarray:\n",
    "    if path.suffix.lower() == \".npy\":\n",
    "        return np.load(path)\n",
    "    return np.squeeze(tiff.imread(str(path)))\n",
    "\n",
    "def first_match(root: Path, patterns: list[str]) -> Path | None:\n",
    "    for p in patterns:\n",
    "        for f in root.glob(p):\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def find_gt_cellbodies(gt_root: Path, core: str) -> np.ndarray:\n",
    "    pats = [f\"{core}_cellbodies.npy\", f\"{core}_cellbodies.tif\", f\"{core}_cellbodies.tiff\"]\n",
    "    f = first_match(gt_root, pats)\n",
    "    if f is None:\n",
    "        raise FileNotFoundError(f\"GT not found for {core}_cellbodies under {gt_root}\")\n",
    "    return load_mask(f)\n",
    "\n",
    "def find_raw_channels(gt_root: Path, core: str) -> tuple[np.ndarray | None, np.ndarray | None]:\n",
    "    # DAPI: {core}.tif|tiff|npy\n",
    "    dapi_fp = first_match(gt_root, [f\"{core}.tif\", f\"{core}.tiff\", f\"{core}.npy\"])\n",
    "    dapi = load_mask(dapi_fp) if dapi_fp else None\n",
    "\n",
    "    # Marker: infer from leading token, else \"_marker\"\n",
    "    leading = core.split(\"_\", 1)[0].lower()\n",
    "    marker_fp = first_match(\n",
    "        gt_root,\n",
    "        [f\"{core}_{leading}.tif\", f\"{core}_{leading}.tiff\", f\"{core}_{leading}.npy\",\n",
    "         f\"{core}_marker.tif\", f\"{core}_marker.tiff\", f\"{core}_marker.npy\"]\n",
    "    )\n",
    "    marker = load_mask(marker_fp) if marker_fp else None\n",
    "\n",
    "    return dapi, marker\n",
    "\n",
    "\n",
    "def make_rgb(dapi: np.ndarray | None, marker: np.ndarray | None) -> np.ndarray | None:\n",
    "    if dapi is None and marker is None:\n",
    "        return None\n",
    "\n",
    "    def to_gray(x: np.ndarray) -> np.ndarray:\n",
    "        x = np.asarray(x)\n",
    "        if x.ndim == 3:\n",
    "            # HÃ—WÃ—C -> single channel\n",
    "            if x.shape[-1] in (3, 4):\n",
    "                # RGB(A) to luminance\n",
    "                x = 0.2126*x[...,0] + 0.7152*x[...,1] + 0.0722*x[...,2]\n",
    "            else:\n",
    "                # treat as z/chan stack -> max-proj\n",
    "                x = x.max(axis=-1)\n",
    "        elif x.ndim > 2:\n",
    "            x = x.squeeze()\n",
    "            if x.ndim > 2:\n",
    "                x = x.max(axis=0)\n",
    "        return x.astype(np.float32)\n",
    "\n",
    "    def norm(x: np.ndarray) -> np.ndarray:\n",
    "        p1, p99 = np.percentile(x, [1, 99]) if x.size else (0, 1)\n",
    "        if p99 <= p1:\n",
    "            p1, p99 = float(x.min()), float(x.max()) if x.max() > x.min() else (0.0, 1.0)\n",
    "        return np.clip((x - p1) / max(p99 - p1, 1e-6), 0, 1)\n",
    "\n",
    "    d = to_gray(dapi)   if dapi   is not None else None\n",
    "    m = to_gray(marker) if marker is not None else None\n",
    "\n",
    "    # align shapes by safe crop to common min size\n",
    "    if d is not None and m is not None:\n",
    "        h = min(d.shape[0], m.shape[0])\n",
    "        w = min(d.shape[1], m.shape[1])\n",
    "        d, m = d[:h, :w], m[:h, :w]\n",
    "        H, W = h, w\n",
    "    else:\n",
    "        base = d if d is not None else m\n",
    "        H, W = base.shape\n",
    "\n",
    "    rgb = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    if d is not None: rgb[..., 2] = norm(d)  # DAPI -> Blue\n",
    "    if m is not None: rgb[..., 1] = norm(m)  # Marker -> Green\n",
    "    return rgb\n",
    "\n",
    "\n",
    "# ---- LOAD ----\n",
    "cyto_path = CYTO_DIR / BASE_FILE\n",
    "assert cyto_path.exists(), f\"missing {cyto_path}\"\n",
    "core = core_from_pred_filename(BASE_FILE)\n",
    "\n",
    "gt = find_gt_cellbodies(GT_DIR, core)\n",
    "orig_pred = load_mask(cyto_path)\n",
    "\n",
    "dapi, marker = find_raw_channels(GT_DIR, core)\n",
    "raw_rgb = make_rgb(dapi, marker)\n",
    "\n",
    "masks = [orig_pred]\n",
    "names = [\"Original_pred_cyto\"]\n",
    "\n",
    "for slug in EXPERIMENT_SLUGS:\n",
    "    p = OUT_ROOT / slug / BASE_FILE\n",
    "    assert p.exists(), f\"missing {p}\"\n",
    "    masks.append(load_mask(p))\n",
    "    names.append(slug)\n",
    "\n",
    "# ---- FIGURE LAYOUT: [GT, RawRGB, Original, ...experiments] ----\n",
    "n_panels = 2 + len(masks)  # GT + Raw + masks\n",
    "fig, axes = plt.subplots(1, n_panels, figsize=(4*n_panels, 4))\n",
    "\n",
    "# GT\n",
    "axes[0].imshow(gt, cmap=\"tab20\")\n",
    "axes[0].set_title(\"GT: _cellbodies\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Raw RGB\n",
    "if raw_rgb is not None:\n",
    "    axes[1].imshow(raw_rgb)\n",
    "    axes[1].set_title(\"Raw: DAPI+Marker\")\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, \"Raw channels not found\", ha=\"center\", va=\"center\")\n",
    "    axes[1].set_title(\"Raw: missing\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Predictions\n",
    "for i, (m, n) in enumerate(zip(masks, names), start=2):\n",
    "    axes[i].imshow(m, cmap=\"tab20\")\n",
    "    axes[i].set_title(n)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# ---- SAVE ----\n",
    "fig_dir = OUT_ROOT / \"figs\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = fig_dir / f\"{core}.png\"\n",
    "plt.savefig(out_path, dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Saved figure -> {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31e277-3a81-4334-9083-840fccaa942a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifimage_evaluation",
   "language": "python",
   "name": "ifimage_evaluation"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
